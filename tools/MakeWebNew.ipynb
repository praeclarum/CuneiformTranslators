{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a01459ea",
   "metadata": {},
   "source": [
    "# Make Web Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902bef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, io, datetime\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "import glob\n",
    "import re\n",
    "import io\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from slugify import slugify\n",
    "from tqdm.notebook import tqdm\n",
    "from html import escape\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6812c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corpi\n",
    "import cdli\n",
    "import oracc\n",
    "import languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6f8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbefe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50f4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_langs = set([\"akk\", \"sux\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b1ed21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/fak/Dropbox/Projects/CuneiformTranslators/dist'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wwwroot = os.path.abspath(\"../dist\")\n",
    "os.makedirs(wwwroot, exist_ok=True)\n",
    "wwwroot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cb499e5",
   "metadata": {},
   "source": [
    "## CDLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc044b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'corpi' from '/Users/fak/Dropbox/Projects/CuneiformTranslators/tools/corpi.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cdli)\n",
    "importlib.reload(oracc)\n",
    "importlib.reload(corpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ecf415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CDLI...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading CDLI...\")\n",
    "cdli_corpus = corpi.CDLI()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bc8c8ae",
   "metadata": {},
   "source": [
    "## ORACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbfe5bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Oracc...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading Oracc...\")\n",
    "oracc_dir=\"/Volumes/FrankDisk/oracc_zips\"\n",
    "oracc_corpus = corpi.ORACC(oracc_dir=oracc_dir, tqdm=tqdm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c762667",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a559bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132,155 unique publications\n"
     ]
    }
   ],
   "source": [
    "all_pubs = corpi.merge_corpus_pubs(\n",
    "    [\n",
    "        (\"oracc\", oracc_corpus.oracc_pubs.values()),\n",
    "        (\"cdli\", cdli_corpus.cdli_pubs.values())\n",
    "    ], supported_langs)\n",
    "print(f\"{len(all_pubs):,} unique publications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e9225c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,444 human translations:\n"
     ]
    }
   ],
   "source": [
    "num_translations = len([x for x in all_pubs.values() if x.has_translations()])\n",
    "print(f\"{num_translations:,} human translations:\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "031eb831",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a42cb4f",
   "metadata": {},
   "source": [
    "## Get the ML Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2741947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akk_to_en 195312\n",
      "sux_to_en 458557\n"
     ]
    }
   ],
   "source": [
    "translations_zip_path = \"../data/ml_translations.zip\"\n",
    "with open(translations_zip_path, \"rb\") as f:\n",
    "    with zipfile.ZipFile(f) as zf:\n",
    "        json_name = [n for n in zf.namelist() if n.endswith(\".json\")][0]\n",
    "        translations = json.loads(str(zf.read(json_name), \"utf-8\"))\n",
    "for k in translations.keys():\n",
    "    if \"_to_\" in k:\n",
    "        print(k, len(translations[k]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2682c03a",
   "metadata": {},
   "source": [
    "## Find Publications that have ML Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8f05720",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_dots_and_spaces = re.compile(r\"^[ .]+$\")\n",
    "\n",
    "def translation_is_good(tgt):\n",
    "    tgt = tgt.strip()\n",
    "    if len(tgt) == 0:\n",
    "        return False\n",
    "    return not just_dots_and_spaces.match(tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a9ba290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01824784278869629,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 132155,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e46e5fdbc14d438c9b502c6682e8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129,705 ml translated pubs\n",
      "115,306 newly translated pubs\n"
     ]
    }
   ],
   "source": [
    "tgt_lang = \"en\"\n",
    "\n",
    "translated_pubs = []\n",
    "\n",
    "for pub in tqdm(list(all_pubs.values())):\n",
    "    has_new_translations = False\n",
    "    has_ml_translations = False\n",
    "    st_key = f\"{pub.language}_to_{tgt_lang}\"\n",
    "    if st_key not in translations:\n",
    "        continue\n",
    "    st_translations = translations[st_key]\n",
    "    for a in pub.text_areas:\n",
    "        if pub.corpus == \"cdli\" and len(a.lines) > 0 and len(a.paragraphs) == 0:\n",
    "            a.lines_to_paragraphs(pub.language, tgt_lang)\n",
    "        paras = a.paragraphs_to_lines(lang=pub.language, corpus_id=pub.corpus)\n",
    "        for i, plines in enumerate(paras):\n",
    "            p = a.paragraphs[i]\n",
    "            p.languages[\"ml_\"+tgt_lang] = \"\"\n",
    "            head = \"\"\n",
    "            for si,ei,s in plines:\n",
    "                s = s.strip()\n",
    "                if len(s) > 1:\n",
    "                    has_lines = True\n",
    "                    if s in st_translations:\n",
    "                        t = st_translations[s].strip()\n",
    "                        if translation_is_good(t) > 0:\n",
    "                            has_new_translations = has_new_translations or (tgt_lang not in p.languages)\n",
    "                            p.languages[\"ml_\"+tgt_lang] += head + st_translations[s]\n",
    "                            head = \" \"\n",
    "                    else:\n",
    "                        # has_ml_translations = False\n",
    "                        # raise Exception(f\"pub {pub.id} has no translation ({st_key}) for: {s}\")\n",
    "                        pass\n",
    "            p.languages[\"ml_\"+tgt_lang] = languages.remove_suffix_repeats(p.languages[\"ml_\"+tgt_lang].strip()).strip()\n",
    "            has_ml_translations = has_ml_translations or len(p.languages[\"ml_\"+tgt_lang]) > 0\n",
    "    pub.has_new_translations = has_new_translations\n",
    "    pub.has_ml_translations = has_ml_translations\n",
    "    if has_ml_translations:\n",
    "        translated_pubs.append(pub.id)\n",
    "    \n",
    "newly_translated_pubs = [x for x in all_pubs.values() if x.has_new_translations]\n",
    "ml_translated_pubs = [x for x in all_pubs.values() if x.has_ml_translations]\n",
    "print(f\"{len(ml_translated_pubs):,} ml translated pubs\")\n",
    "print(f\"{len(newly_translated_pubs):,} newly translated pubs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2c5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99295, 'sux')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in translated_pubs if all_pubs[x].language == \"sux\"]), \"sux\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81004c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Publication('P468981', 'akk', [TextArea('tablet', [], []), TextArea('obverse', [TextLine('1.', '[a-na {d}]marduk#? kab#-tu szit-ra-hu {d}en-lil2 _dingir-mesz_ sza2-qu-u2', {}), TextLine('2.', '[e-li _dingir]-mesz#_ a-szir# _dingir-mesz_ ka-la-me mu-kil mar-kas {d}i2-gi3-gi3', {}), TextLine('3.', \"[u3 {d}a]-nun#-na-ki mu-ma-'e-er _dingir_ ku-na _lugal szu2 an_-e u3 _ki_-tim\", {}), TextLine('4.', 'sza2#? a#?-na#? zik#-ri-szu2 _dingir-mesz gal-mesz_ pal#-hisz u2-taq-qu-u2 qi2-bit-su', {}), TextLine('5.', 'szah-tu2 la-a-nu szi-i-hu sza2 ina _zu-ab_ ir-bu-u2 bal-ti szur-ru-hu', {}), TextLine('6.', \"mi3-na-a-ta szu-tu-ru s,u-ub-bu-u2 nab-ni-ti le-e'-um\", {}), TextLine('7.', \"le-e'-u2-tu mu-du-u2 ka-la-me la-mid t,e3-em _zu-ab_\", {}), TextLine('8.', 'a-hi-iz pi-risz-ti lal3-gar _en_ babila2{ki}', {}), TextLine('9.', 'a-szib e2-sag-il2 _en gal_-u2 _en szu2 {disz}an-szar2-e-tel-li-dingir-mesz_', {}), TextLine('10.', '_lugal szu2 lugal kur_ an-szar2{ki} _{gesz}banszur {gesz}mes-ma2-kan-na_', {}), TextLine('11.', 'is,-s,i da-ru-u2 sza2# s,a#-ri-ri _husz-a_ uh-hu-zu', {})], [TextParagraph(0, 7, {'ml_en': 'To Marduk, the strong, the exalted, the Enlil of the gods, the exalted one, above the gods, the one who oversees all the gods, the one who binds the bonds of the Igigu and Anunnaku gods, the one who accepts the god, the true king, king of heaven and earth, whose command the great gods are praised, the unceasing, the unceasing, the unceasing, who in the apsû he has sworn, the slanderer, the'}), TextParagraph(7, 11, {'ml_en': 'who bears the secrets of Lalgar, lord of Babylon, who dwells in Esagil, great lord, lord of Ashur-etel-ilani, king of the world, king of Assyria, a table and a musukkannu-tree, a durable wooden object that is clad with fiery radiance,'})]), TextArea('reverse', [TextLine('1.', '_sza2 nu kat2 masz_ x', {}), TextLine('2.', '[i]-na# szi-pir _dumu#-me_ um#-ma#-nu# nak#-lisz szu-pu-szu2 a-na si-ma-a-ta', {}), TextLine('3.', 'ma#-ka#-le#-e _ku3-me_ szu-lu-ku a-na _din zi-mesz_-szu2 sze-me-e', {}), TextLine('4.', 'su-pe-e-szu2 sa-kap _{lu2}kur2-mesz_-szu2 _ba_-isz3', {}), TextLine('5.', '{d}marduk _en gal_-u2 _{gesz}banszur_ szu-a-ti', {}), TextLine('6.', 'ha-disz ina nap-lu-si-ka {d}szul-pa-e3-a _en {gesz}banszur_', {}), TextLine('7.', 'ina ra-kas _{gesz}banszur_ sza2-rak sur-qin-nu ka-a-a-an la na-par-ka-a', {}), TextLine('8.', 'a-mat _{munus}saga {disz}an-szar2-e-tel-li-dingir-me lugal kur_ an-szar2{ki}', {}), TextLine('9.', '_nun_ mi-gir lib3-bi-ka lit-tas-qar ma-har-ka', {}), TextLine('10.', '2(disz) _sila3_ 3(disz) szal-szu2 _ninda siskur_ 1(disz) _(pi)_ 1(disz) _(ban2) {gesz}pesz3 had2-a_ ina masz-szar-ti sza2 _{iti}du6_', {}), TextLine('11.', '{disz}na-din _a_ {disz}{d}en-pap-me-ba-sza2 _{iti}kin u4 1(u) 1(disz)-kam mu 3(disz)-kam_', {})], [TextParagraph(0, 9, {'ml_en': \"... by the craft of the skilled craftsmen, to the right and left of the holy rites to be performed, to give his life, to hear his prayers, to defeat his enemies, to smite Marduk, the great lord, this table with joy, Shulpa'e'a, the lord of this table, to the ... of the table, the strewn offering, without interruption, the word of good fortune of Ashurbanipal, king of Assyria,\"}), TextParagraph(9, 10, {'ml_en': '2 qû 3 half-shekels of siskur-bread, 1 panu 1 sutu of figs, ..., in the mashartu of month VII,'}), TextParagraph(10, 11, {'ml_en': 'Nadin, son of Bel-papmebasha; 11th day of Ululu, 3rd year of Bel-eter, king of Assyria.'})])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newly_translated_pubs[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "084d96c7",
   "metadata": {},
   "source": [
    "## Filter out publications with no translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd7152d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129,705 publications to output\n"
     ]
    }
   ],
   "source": [
    "def keep_pub(pub):\n",
    "    if not pub.has_ml_translations:\n",
    "        return False\n",
    "    return pub.is_translated(\"ml_en\")\n",
    "\n",
    "all_pubs = {k:v for k,v in all_pubs.items() if v.has_ml_translations}\n",
    "print(f\"{len(all_pubs):,} publications to output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2a505f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 publication directories\n"
     ]
    }
   ],
   "source": [
    "# Group publications by the first 4 characters of pub.id to create a directory structure\n",
    "all_pubs_by_dir = defaultdict(list)\n",
    "for p in all_pubs.values():\n",
    "    all_pubs_by_dir[p.id[:4].lower()].append(p)\n",
    "print(f\"{len(all_pubs_by_dir):,} publication directories\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3ce1738",
   "metadata": {},
   "source": [
    "## Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f2d4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser_dimensions = [\n",
    "#     (\"new\", lambda p: [\"new\" if p.has_new_translations else \"old\"]),\n",
    "#     (\"language\", lambda p: [p.language]),\n",
    "    (\"object_type\", lambda p: [cdli.get_object_type(p.object_type)]),\n",
    "    (\"genre\", lambda p: cdli.get_genres(p.genre)),\n",
    "    (\"period\", lambda p: [cdli.period_slug_from_period[x] for x in cdli.get_periods(p.period)]),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec4f988c",
   "metadata": {},
   "source": [
    "## HTML Components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cdf4c54",
   "metadata": {},
   "source": [
    "## HTML Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8db67ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(site_path):\n",
    "    return f\"{wwwroot}{site_path}\"\n",
    "\n",
    "def get_page_file_path(site_path):\n",
    "    return f\"{get_file_path(site_path)}.html\"\n",
    "\n",
    "def get_json_file_path(site_path):\n",
    "    return f\"{get_file_path(site_path)}.json\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba8f429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def header(paths_and_titles, f):\n",
    "    title = paths_and_titles[-1][1]\n",
    "    f.write(f\"<!DOCTYPE html>\\n\")\n",
    "    f.write(f\"<html>\\n<head>\\n\")\n",
    "    f.write(f\"<meta charset='utf-8'>\\n\")\n",
    "    f.write(f\"<title>{escape(title)}</title>\\n\")\n",
    "    f.write(f\"<meta name='viewport' content='width=device-width, initial-scale=1'>\\n\")\n",
    "    f.write(f\"<link rel='stylesheet' href='/main.css'>\\n\")\n",
    "    f.write(f\"</head>\\n\")\n",
    "    f.write(f\"<body>\\n\")\n",
    "    f.write(f\"<header><h1 id='page-title'>\")\n",
    "    f.write(f\"<a href='/'>AICC</a>\")\n",
    "    for i, (path, title) in enumerate(paths_and_titles):\n",
    "        f.write(f\" / \")\n",
    "        if i < len(paths_and_titles) - 1:\n",
    "            abs_path = \"/\" + \"/\".join([x[0] for x in paths_and_titles[:i+1]])\n",
    "            f.write(f\"<a href='{abs_path}/'>{escape(title)}</a>\")\n",
    "        else:\n",
    "            f.write(f\"{escape(title)}\")\n",
    "    f.write(f\"</h1>\\n\")\n",
    "    f.write(f\"<form id='search-form' action='/search.html' method='get'>\\n\")\n",
    "    f.write(f\"<input type='text' id='search-input' name='q' autocomplete='off' autocapitalize='off' autocorrect='off' spellcheck='false' placeholder='Search...'>\\n\")\n",
    "    f.write(f\"</form>\\n\")\n",
    "    f.write(f\"</header>\\n\")\n",
    "    f.write(f\"<div class='content'>\\n\")\n",
    "    \n",
    "def footer(f, script=None):\n",
    "    f.write(f\"</div>\\n\")\n",
    "    f.write(f\"<footer>\\n\")\n",
    "    f.write(f\"<p class='otitle'>Code by&nbsp;<a class='external' href='https://github.com/praeclarum/CuneiformTranslators'>praeclarum</a> — AI&nbsp;Translations by <a class='external' href='https://huggingface.co/praeclarum/cuneiform'>praeclarum/cuneiform</a></p>\\n\")\n",
    "    f.write(f\"</footer>\\n\")\n",
    "    f.write(f\"<script src='/main.js'></script>\\n\")\n",
    "    if script is not None:\n",
    "        f.write(f\"<script>{script}</script>\\n\")\n",
    "    f.write(f\"</body>\\n</html>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb66f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_page(paths_and_titles):\n",
    "    paths = [x[0] for x in paths_and_titles]\n",
    "    path = \"/\" + \"/\".join(paths)\n",
    "    file_path = get_page_file_path(path)\n",
    "    file_dir = os.path.dirname(file_path)\n",
    "    os.makedirs(file_dir, exist_ok=True)\n",
    "    f = open(file_path, \"wt\")\n",
    "#     print(f\"Writing {path} at {file_path}\")\n",
    "    header(paths_and_titles, f)\n",
    "    return f\n",
    "\n",
    "def end_page(f):\n",
    "    footer(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a14c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_json(path):\n",
    "    file_path = get_json_file_path(path)\n",
    "    file_dir = os.path.dirname(file_path)\n",
    "    os.makedirs(file_dir, exist_ok=True)\n",
    "    f = open(file_path, \"wt\")\n",
    "    return f\n",
    "\n",
    "def end_json(f):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59744f1f",
   "metadata": {},
   "source": [
    "### Publication Index Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b8a546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_links = [\n",
    "    (\"Oracc - Open Richly Annotated Cuneiform Corpus\", \"http://oracc.museum.upenn.edu\"),\n",
    "    (\"CDLI - Cuneiform Digital Library Initiative\", \"https://cdli.ucla.edu\"),\n",
    "    (\"ETCSL - Electronic Text Corpus of Sumerian Literature\", \"https://etcsl.orinst.ox.ac.uk\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfc8f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_sort = {\n",
    "    \"akk\": 0,\n",
    "#     \"akkts\": 1,\n",
    "#     \"elx\": 2,\n",
    "#     \"elxts\": 3,\n",
    "    \"sux\": 4,\n",
    "#     \"suxts\": 5,\n",
    "    \"ml_en\": 100,\n",
    "    \"en\": 1000,\n",
    "#     \"fr\": 1001,\n",
    "}\n",
    "\n",
    "bad_translators = {\"uncertain\", \"NaN\", \"no translation\", \"\", \"check\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "109c8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraphs_to_html(a, paragraphs, lang, corpus):\n",
    "    html = []\n",
    "    for pi, plines in enumerate(paragraphs):\n",
    "        p = a.paragraphs[pi]\n",
    "        text = \"\"\n",
    "        if lang in p.languages:\n",
    "            text = p.languages[lang]\n",
    "            if not lang.startswith(\"ml_\"):\n",
    "                text = languages.prep_tgt_for_nn(text, lang, corpus)\n",
    "        else:\n",
    "            text = \" \".join(x for (_, _, x) in plines)\n",
    "        tag = p.tag\n",
    "        html.append(f\"<{tag}>\")\n",
    "        line_index = plines[0][0] if len(plines) > 0 else 0\n",
    "        html.append(f\"<span class='line line-{line_index}'>{escape(text)}</span>\\n\")\n",
    "        html.append(f\"</{tag}>\\n\")\n",
    "    return \"\".join(html)\n",
    "\n",
    "def title_case(str):\n",
    "    if len(str) == 0:\n",
    "        return str\n",
    "    if len(str) == 1:\n",
    "        return str.upper()\n",
    "    return str[0].upper() + str[1:]\n",
    "\n",
    "def output_pub(p, f):\n",
    "    if p.id in [\"P229313\"]:\n",
    "        print(cdli.pub_to_json(p))\n",
    "        return\n",
    "    pdir = p.id.lower()[:4]\n",
    "    f.write(f\"<h1 class='otitle'><a href='/p/{pdir}.html#{p.id}'>{p.id}</a>: {' and '.join(cdli.get_genres(p.genre))} {cdli.get_object_type(p.object_type)}</h1>\\n\")\n",
    "    src_a = \"\"\n",
    "    if p.corpus == \"cdli\":\n",
    "        src_a = f\"<a class='external' href='https://cdli.ucla.edu/search/archival_view.php?ObjectID={p.id}'>CDLI</a>\"\n",
    "    else:\n",
    "        src_a = f\"<a class='external' href='{p.src_url}'>Oracc</a>\"\n",
    "    f.write(f\"<p class='otitle'>{p.period} {src_a}</p>\\n\")\n",
    "    areas_with_paras = [x for x in p.text_areas if len(x.lines) > 0 and len(x.paragraphs) > 0]\n",
    "    for a in areas_with_paras:\n",
    "        f.write(f\"<section class='textarea'>\\n\")\n",
    "        if len(areas_with_paras) > 1:\n",
    "            f.write(f\"<h1>{escape(title_case(a.name))}</h1>\\n\")\n",
    "        f.write(f\"<div class='translations-container'>\\n\")\n",
    "        paragraphs = a.paragraphs_to_lines(p.language, corpus_id=p.corpus)\n",
    "        texts = {p.language: paragraphs_to_html(a, paragraphs, p.language, p.corpus)}\n",
    "        langs = set()\n",
    "        for para in a.paragraphs:\n",
    "            for lang in para.languages:\n",
    "                if lang in language_sort:\n",
    "                    langs.add(lang)\n",
    "        for lang in langs:\n",
    "            texts[lang] = paragraphs_to_html(a, paragraphs, lang, p.corpus)\n",
    "        langs.add(p.language)\n",
    "#             f.write(f\"<p><pre>{escape(repr(paragraphs))}</pre></p> \")\n",
    "#             if \"akkts\" in langs and \"akk\" in langs:\n",
    "#                 langs.remove(\"akk\")\n",
    "#             if \"suxts\" in langs and \"sux\" in langs:\n",
    "#                 langs.remove(\"sux\")\n",
    "        langs = sorted(list(langs), key=lambda x:language_sort[x])\n",
    "        for lang in langs:\n",
    "            f.write(f\"<div class='lang-{lang} text'>\\n\")\n",
    "            translator = \"AI Translation\" if lang.startswith(\"ml_\") else (languages.all_languages[lang])\n",
    "            if lang == tgt_lang:\n",
    "                if p.translation_source is not None and p.translation_source not in bad_translators:\n",
    "                    translator = escape(p.translation_source)\n",
    "                else:\n",
    "                    translator = \"Human\"\n",
    "            f.write(f\"<div class='langid'>{translator}</div>\\n\")\n",
    "            f.write(texts[lang])\n",
    "            f.write(f\"</div>\\n\")\n",
    "        f.write(f\"</div></section>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9338890e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008517980575561523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 12,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a32de53138e4963907b1ec701f131de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with start_page([(\"p/index\", \"Publications\")]) as f:\n",
    "    pdirs = sorted(list(all_pubs_by_dir.keys()))\n",
    "    groups = defaultdict(list)\n",
    "    for pdir in pdirs:\n",
    "        groups[pdir[:2]].append(pdir)\n",
    "    f.write(f\"<div class='publications-list-container'>\\n\")\n",
    "    for gid, gpdirs in tqdm(groups.items()):\n",
    "        first_dir = gpdirs[0]\n",
    "        first_pub = sorted(all_pubs_by_dir[first_dir], key=lambda p:p.id)[0]\n",
    "        last_dir = gpdirs[-1]\n",
    "        last_pub = sorted(all_pubs_by_dir[last_dir], key=lambda p:p.id)[-1]\n",
    "        f.write(f\"<section id='{gid}' class='publications-list'>\\n\")\n",
    "        f.write(f\"<h1>{first_pub.id} - {last_pub.id}</h1>\\n\")\n",
    "        f.write(f\"<ul>\\n\")\n",
    "        for pdir in gpdirs:\n",
    "            pubs = sorted(all_pubs_by_dir[pdir], key=lambda p:p.id)\n",
    "            f.write(f\"<li><a href='/p/{pdir}.html'>{pubs[0].id} - {pubs[-1].id}</a></li>\\n\")\n",
    "        f.write(f\"</ul>\\n\")\n",
    "        f.write(f\"</section>\\n\")\n",
    "    f.write(f\"</div>\\n\")\n",
    "    end_page(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e67923b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008578062057495117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 376,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf49c0494e364e58956e259c81297cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for pdir in tqdm(sorted(list(all_pubs_by_dir.keys()))):\n",
    "    pubs = sorted(all_pubs_by_dir[pdir], key=lambda p:p.id)\n",
    "    with start_page([(\"p\", \"Publications\"), (pdir, pdir)]) as f:\n",
    "        f.write(f\"<div class='pubs-container'>\\n\")\n",
    "        for p in pubs:\n",
    "            f.write(f\"<section id='{p.id}' class='pub'>\\n\")\n",
    "            output_pub(p, f)\n",
    "            f.write(f\"</section>\\n\")\n",
    "        f.write(f\"</div>\\n\")\n",
    "        end_page(f)\n",
    "    with start_json(f\"/p/{pdir}\") as f:\n",
    "        f.write(\"{\\n\")\n",
    "        head = \"\"\n",
    "        for p in pubs:\n",
    "            pjson = {}\n",
    "            phtml = io.StringIO()\n",
    "            output_pub(p, phtml)\n",
    "            pjson[\"html\"] = phtml.getvalue()\n",
    "            pjson = json.dumps(pjson)\n",
    "            f.write(f\"{head}\\\"{p.id}\\\": {pjson}\")\n",
    "            head = \",\\n\"\n",
    "        f.write(\"\\n}\\n\")\n",
    "        end_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc86942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed5050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f48c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe126897",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{wwwroot}/fonts\", exist_ok=True)\n",
    "for font in glob.glob(\"../fonts/*.woff\"):\n",
    "    shutil.copy2(font, f\"{wwwroot}/fonts/{os.path.basename(font)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0574a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "with start_page([(\"404\", \"Not Found\")]) as f:\n",
    "    f.write(f\"<p>The page you are looking for is not here.</p>\\n\")\n",
    "    footer(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a60486b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/fak/Dropbox/Projects/CuneiformTranslators/dist/main.js'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(\"../web/translator.html\", f\"{wwwroot}/translator.html\")\n",
    "shutil.copy(\"../web/main.css\", f\"{wwwroot}/main.css\")\n",
    "shutil.copy(\"../web/main.js\", f\"{wwwroot}/main.js\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "daf283d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc98b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50fcb7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with start_page([(\"search\", \"Search\")]) as f:\n",
    "    f.write(f\"<div id='search'></div>\\n\")\n",
    "    script = \"\"\"\n",
    "    // get the q query parameter\n",
    "    const q = new URLSearchParams(window.location.search).get('q');\n",
    "    (async function() {\n",
    "        const s = new PublicationSearch(document.getElementById('search'), document.getElementById('search-input'), q);\n",
    "        if (q) {\n",
    "            await s.searchAsync(q, true);\n",
    "        }\n",
    "    })();\"\"\"\n",
    "    footer(f, script=script)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e05fc59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_number_re = re.compile(r\"^[a-z][0-9]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09746060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007968902587890625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 129705,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14e0a2a3ae04fbe94a65a844ba9e69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157477 words in index\n"
     ]
    }
   ],
   "source": [
    "en_index = defaultdict(set)\n",
    "en_histogram = defaultdict(int)\n",
    "en_pub_histogram = defaultdict(lambda: defaultdict(int))\n",
    "for p in tqdm(all_pubs.values()):\n",
    "    for a in p.text_areas:\n",
    "        for para in a.paragraphs:\n",
    "            if \"ml_en\" in para.languages:\n",
    "                text = para.languages[\"ml_en\"]\n",
    "                words = text.split()\n",
    "                for word in words:\n",
    "                    w = word.lower().replace(\"\\\"\", \"\").replace(\"'\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").replace(\":\", \"\").replace(\"?\", \"\").replace(\"!\", \"\").replace(\"”\", \"\").replace(\"“\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"{\", \"\").replace(\"}\", \"\").replace(\"’\", \"\").replace(\"‘\", \"\").replace(\"…\", \"\").replace(\"+\", \"\").replace(\"$\", \"\").replace(\"*\", \"\").replace(\"/\", \"\").replace(\"\\\\\", \"\").replace(\"=\", \"\").replace(\">\", \"\").replace(\"<\", \"\").replace(\"|\", \"\")\n",
    "                    w = w.strip(\"-\").strip(\"_\").strip()\n",
    "                    is_number = len(w) > 1 and w[0] in \"0123456789\" or (letter_number_re.match(w) is not None)\n",
    "                    if not is_number and len(w) > 1 and len(w) < 64 and w not in languages.en_index_ignore_words:\n",
    "                        en_index[w].add(p.id)\n",
    "                        en_histogram[w] += 1\n",
    "                        en_pub_histogram[w][p.id] += 1\n",
    "print(len(en_index), \"words in index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ee5861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157477 histogram words\n"
     ]
    }
   ],
   "source": [
    "print(len(en_histogram), \"histogram words\")\n",
    "# Get the most common words\n",
    "# en_common = sorted(list(en_histogram.items()), key=lambda x:-x[1])[:100]\n",
    "# for w, c in en_common:\n",
    "#     print(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7864363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group en_index by first letter\n",
    "en_index_by_letter = defaultdict(dict)\n",
    "for word in en_index:\n",
    "    en_index_by_letter[word[0]][word] = en_index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedeb095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c177640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_index(lang):\n",
    "    with start_page([(f\"{lang}_index/index\", f\"{languages.all_languages[lang]} Index\")]) as f:\n",
    "        f.write(f\"<div class='text-container'><div>\\n\")\n",
    "        f.write(f\"<p>{len(en_index):,} Indexed Words</p>\\n\")\n",
    "        f.write(f\"<p>\\n\")\n",
    "        for letter in sorted(list(en_index_by_letter.keys())):\n",
    "            f.write(f\"<span><a href='#{letter}'>{letter}</a></span>\\n\")\n",
    "        f.write(f\"</p>\\n\")\n",
    "        f.write(f\"</div></div>\\n\")\n",
    "        f.write(f\"<div class='browsedims-container'>\\n\")\n",
    "        all_two_letters = defaultdict(list)\n",
    "        for letter in sorted(list(en_index_by_letter.keys())):\n",
    "            two_letters = defaultdict(list)\n",
    "            words = sorted(list(en_index_by_letter[letter].keys()))\n",
    "            for word in words:\n",
    "                two_letters[word[:2]].append(word)\n",
    "                all_two_letters[word[:2]].append(word)\n",
    "            f.write(f\"<div>\\n\")\n",
    "            f.write(f\"<h2 id='{letter}'>{escape(words[0])} - {escape(words[-1])}</h2>\\n\")\n",
    "            f.write(f\"<ul>\\n\")\n",
    "            for prefix in sorted(list(two_letters.keys())):\n",
    "                twords = sorted(list(two_letters[prefix]))\n",
    "                f.write(f\"<li><a href='/en_index/{prefix}.html'>{escape(twords[0])} - {escape(twords[-1])}</a></li>\\n\")\n",
    "            f.write(f\"</ul>\\n\")\n",
    "            f.write(f\"</div>\\n\")\n",
    "        f.write(f\"</div>\\n\")\n",
    "        script = \"\"\"\n",
    "        \"\"\"\n",
    "        footer(f, script=script)\n",
    "    return all_two_letters\n",
    "two_letters = output_index(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a501a47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008149147033691406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 424,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af416d1c34fa4b24871e0eb34515200f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/424 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def output_index_json(lang=\"en\"):\n",
    "    for prefix in tqdm(sorted(list(two_letters.keys()))):\n",
    "        words = sorted(two_letters[prefix])\n",
    "        title = f\"{words[0]} - {words[-1]}\"\n",
    "        with start_page([(\"en_index\", f\"{languages.all_languages[lang]} Index\"), (prefix, title)]) as f:\n",
    "            f.write(f\"<div class='browsedims-container'>\\n\")\n",
    "            f.write(f\"<ul>\\n\")\n",
    "            for word in sorted(list(two_letters[prefix])):\n",
    "                f.write(f\"<li><a href='/search.html?q={word}'>{word}</a> ({len(en_index[word]):,})</li>\\n\")\n",
    "            f.write(f\"</ul>\\n\")\n",
    "            f.write(f\"</div>\\n\")\n",
    "            footer(f)\n",
    "        with start_json(f\"/en_index/{prefix}\") as f:\n",
    "            words = two_letters[prefix]\n",
    "            word_json = {word: [(p, en_pub_histogram[word][p]) for p in en_index[word]] for word in words}\n",
    "            json.dump(word_json, f, indent=0)\n",
    "output_index_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409dbb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1d6dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_browser(paths_and_titles, pubs, ignore_dims, f, include_browser=True):\n",
    "    next_pages = []\n",
    "    if len(pubs) == 0:\n",
    "        return next_pages\n",
    "    f.write(f\"<div id='browser'></div>\\n\")\n",
    "    f.write(f\"<nav class='browsedims-container'>\\n\")\n",
    "    for dname, dselect in browser_dimensions:\n",
    "        if dname in ignore_dims:\n",
    "            continue\n",
    "        vgroups = defaultdict(lambda: [])\n",
    "        for p in pubs:\n",
    "            for v in dselect(p):\n",
    "                vgroups[v].append(p)\n",
    "        if len(vgroups) < 2:\n",
    "            continue\n",
    "        f.write(f\"<section>\\n\")\n",
    "        f.write(f\"<h1>{escape(dname)}</h1>\\n\")    \n",
    "        for gv in vgroups.keys():\n",
    "            gpubs = vgroups[gv]\n",
    "            if len(gpubs) > 0:\n",
    "                next_pages.append((dname, gv, gpubs))\n",
    "                f.write(f\"<a href='{gv}/'>{len(gpubs):,}&nbsp;{escape(gv)}</a>\\n\")\n",
    "        f.write(f\"</section>\\n\")\n",
    "    f.write(f\"</nav>\\n\")\n",
    "    if include_browser:\n",
    "        f.write(f\"<script>\\n\")\n",
    "        f.write(f\"const publicationIds = {json.dumps(sorted([p.id for p in pubs]))};\\n\")\n",
    "        f.write(f\"</script>\\n\")\n",
    "    # f.write(f\"<section>\\n\")\n",
    "    # max_on_page = 200\n",
    "    # if len(pubs) <= max_on_page or len(next_pages) == 0:\n",
    "    #     for p in pubs:\n",
    "    #         output_pub(p, f)        \n",
    "    # else:\n",
    "    #     f.write(f\"<p>{len(pubs):,} publications. Narrow the list to less than {max_on_page:,} by choosing links above.</p>\\n\")\n",
    "    # f.write(f\"</section>\\n\")\n",
    "    footer(f, script=\"makePublicationBrowser(document.getElementById('browser'), publicationIds);\" if include_browser else None)\n",
    "    return next_pages\n",
    "\n",
    "def output_browser_page(parent_paths_and_titles, dim_value, pubs, ignore_dims):\n",
    "    paths_and_titles = parent_paths_and_titles + [(dim_value + \"/index\", dim_value)]\n",
    "    with start_page(paths_and_titles) as f:\n",
    "        next_pages = output_browser(paths_and_titles, pubs, ignore_dims, f)\n",
    "    paths_and_titles = parent_paths_and_titles + [(dim_value, dim_value)]\n",
    "    for gk, gv, gpubs in next_pages:\n",
    "        ignores = set(ignore_dims)\n",
    "        ignores.add(gk)\n",
    "        output_browser_page(paths_and_titles, gv, gpubs, ignores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b54ec692",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007628917694091797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 80,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6553901efe043a0bfb5200c6b8bbabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dist/eponym-chronicle\n",
      "../dist/akk\n",
      "../dist/omen\n",
      "../dist/extispicy-query\n",
      "../dist/priestly-letter\n",
      "../dist/other-genre\n",
      "../dist/tablet\n",
      "../dist/appointment\n",
      "../dist/uruk-iii\n",
      "../dist/index.html\n",
      "../dist/lexical\n",
      "../dist/uncertain\n",
      "../dist/parthian\n",
      "../dist/treaty\n",
      "../dist/lexical-mathematical\n",
      "../dist/incantation-ritual\n",
      "../dist/hellenistic\n",
      "../dist/hemerological\n",
      "../dist/royal-inscription\n",
      "../dist/scholarly-letter\n",
      "../dist/ur-iii\n",
      "../dist/barrel\n",
      "../dist/private-votive\n",
      "../dist/astrological\n",
      "../dist/votive-donation\n",
      "../dist/scholarly\n",
      "../dist/old-akkadian\n",
      "../dist/prism\n",
      "../dist/404.html\n",
      "../dist/cone\n",
      "../dist/ed-i-ii\n",
      "../dist/letter\n",
      "../dist/other-period\n",
      "../dist/astronomical-diary\n",
      "../dist/main.css\n",
      "../dist/early-neo-babylonian\n",
      "../dist/en_index\n",
      "../dist/old-babylonian\n",
      "../dist/ed-iiib\n",
      "../dist/seal\n",
      "../dist/vase\n",
      "../dist/other-object\n",
      "../dist/neo-babylonian\n",
      "../dist/astronomical\n",
      "../dist/royal-ritual\n",
      "../dist/gift\n",
      "../dist/early-old-babylonian\n",
      "../dist/bulla\n",
      "../dist/neo-assyrian\n",
      "../dist/decree\n",
      "../dist/old-assyrian\n",
      "../dist/main.js\n",
      "../dist/historical\n",
      "../dist/envelope\n",
      "../dist/achaemenid\n",
      "../dist/ebla\n",
      "../dist/inscription-on-a-perle\n",
      "../dist/sux\n",
      "../dist/translator.html\n",
      "../dist/administrative\n",
      "../dist/middle-assyrian\n",
      "../dist/technical-procedure\n",
      "../dist/legal-transaction\n",
      "../dist/brick\n",
      "../dist/seleucid\n",
      "../dist/medical\n",
      "../dist/vessel\n",
      "../dist/hymn-prayer\n",
      "../dist/prophecy\n",
      "../dist/lentil\n",
      "../dist/search.html\n",
      "../dist/extispicy-report\n",
      "../dist/sealing\n",
      "../dist/ritual\n",
      "../dist/royal-monumental\n",
      "../dist/literary-work\n",
      "../dist/mathematical\n",
      "../dist/prayer-incantation\n",
      "../dist/royal-stone-inscription\n",
      "../dist/fake\n",
      "../dist/middle-babylonian\n",
      "../dist/lagash-ii\n",
      "../dist/legal\n",
      "../dist/middle-hittite\n",
      "../dist/fonts\n",
      "../dist/eponym-list\n",
      "../dist/school\n",
      "../dist/cylinder\n",
      "../dist/tag\n",
      "../dist/middle-elamite\n",
      "../dist/grant\n",
      "../dist/block\n",
      "../dist/p\n",
      "../dist/literary\n",
      "../dist/scientific\n",
      "../dist/ed-iiia\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cdli)\n",
    "print(\"Writing /\")\n",
    "with start_page([(\"index\", \"AI Cuneiform Corpus\")]) as f:\n",
    "    f.write(f\"<div class='text-container'>\")\n",
    "    f.write(f\"<section>\\n\")\n",
    "    f.write(f\"<p>The Largest Online Corpus of Translated Cuneiform Texts</p>\\n\")\n",
    "    # f.write(f\"<a href='/translator'>Online Translator!</a>\")\n",
    "#     pubs = [p for p in output_pubs if p.id>393000 and p.id<394000]\n",
    "    by_lang = defaultdict(lambda: [])\n",
    "    for p in all_pubs.values():\n",
    "        by_lang[p.language].append(p)\n",
    "    next_pages = []\n",
    "    f.write(f\"<nav>\\n\")\n",
    "    f.write(f\"<ul>\\n\")\n",
    "    f.write(f\"<li><a href='/p/'>{len(all_pubs):,} Translated Cuneiform Publications</a></li>\\n\")\n",
    "    for lang in sorted(list(by_lang.keys())):\n",
    "        gpubs = by_lang[lang]\n",
    "        # f.write(f\"<li><a href='browse.html?q={lang}'>{len(gpubs):,} {escape(lang)}</a></li>\\n\")\n",
    "        f.write(f\"<li><a href='/{lang}/'>{len(gpubs):,} from {escape(languages.all_languages[lang])}</a></li>\\n\")\n",
    "        next_pages.append((\"language\", lang, gpubs))\n",
    "    f.write(f\"<li><a href='/en_index/'>English Index</a></li>\\n\")\n",
    "    f.write(f\"</ul>\\n\")\n",
    "    f.write(f\"</nav>\\n\")\n",
    "    f.write(f\"</section>\\n\")\n",
    "    f.write(f\"</div>\")\n",
    "    next_pages.extend(output_browser(\"\", list(all_pubs.values()), \"\", f, include_browser=False))\n",
    "    \n",
    "for gk, gv, gpubs in tqdm(next_pages):\n",
    "    output_browser_page([], gv, gpubs, set([gk]))\n",
    "    pass\n",
    "    \n",
    "for f in glob.glob(\"../dist/*\"):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de62125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad953753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7b02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af7efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad79482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411758e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe8d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
