{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc91511",
   "metadata": {},
   "source": [
    "# Infer\n",
    "\n",
    "First, make paragraphs from lines (unwrap), then wrap to the limits of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f9b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 09:56:31.651575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-08 09:56:31.765969: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-08 09:56:32.167052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:\n",
      "2023-06-08 09:56:32.167099: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:\n",
      "2023-06-08 09:56:32.167104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, datetime\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TranslationPipeline\n",
    "from collections import defaultdict\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb5e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d0039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982f75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_langs = set([\"akk\", \"sux\"])\n",
    "tgt_langs = set([\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b168db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"praeclarum/cuneiform\"\n",
    "# model_revision = \"1ba74c8dcf6d1839b0a56589a53dfb5c20ca84f2\"\n",
    "# model_revision = \"7a60be19efe61bf4adf873eb86f864ea7bfb4876\"\n",
    "model_revision = \"02d6e0940c949f88c70ac3e49dbbf072cf645b92\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d4fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device = \"cuda\" if torch.has_cuda else \"cpu\"\n",
    "device_id = 0 if device == \"cuda\" else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec28e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun  8 09:57:10 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   33C    P8    26W / 350W |    351MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1109      G   /usr/lib/xorg/Xorg                 64MiB |\r\n",
      "|    0   N/A  N/A      1354    C+G   ...ome-remote-desktop-daemon      255MiB |\r\n",
      "|    0   N/A  N/A      1390      G   /usr/bin/gnome-shell               22MiB |\r\n",
      "|    0   N/A  N/A     21382      G   gnome-control-center                4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1616e0d",
   "metadata": {},
   "source": [
    "## Load Existing Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e594ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json_path = \"../data/ml_translations.json\"\n",
    "output_zip_path = output_json_path.replace(\".json\", \".zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388db15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91014 sux\n",
      "14170 akk\n"
     ]
    }
   ],
   "source": [
    "with open(output_zip_path, \"rb\") as zipf:\n",
    "    with zipfile.ZipFile(zipf) as zf:\n",
    "        name = [x for x in zf.namelist() if x.endswith(\".json\")][0]\n",
    "        with zf.open(name) as f:\n",
    "            old_translations = json.loads(str(f.read(), \"utf8\"))\n",
    "print(len(old_translations[\"sux_to_en\"]), \"sux\")\n",
    "print(len(old_translations[\"akk_to_en\"]), \"akk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbee98ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_id', 'model_revision', 'akk_to_en', 'sux_to_en'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_translations = dict(old_translations)\n",
    "new_translations.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d6be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_translations[\"model_revision\"] != model_revision:\n",
    "    print(\"Clearing defunct translations\")\n",
    "    for s_lang in src_langs:\n",
    "        for t_lang in tgt_langs:\n",
    "            st_key = f\"{s_lang}_to_{t_lang}\"\n",
    "            new_translations[st_key] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d78d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91014 sux\n",
      "14170 akk\n"
     ]
    }
   ],
   "source": [
    "# Remove blank translations\n",
    "for s_lang in src_langs:\n",
    "    for t_lang in tgt_langs:\n",
    "        st_key = f\"{s_lang}_to_{t_lang}\"\n",
    "        ts = new_translations[st_key]\n",
    "        srcs = list(ts.keys())\n",
    "        for s in srcs:\n",
    "            if s in ts and len(ts[s].strip()) == 0:\n",
    "                print(\"Bad translation: \" + s)\n",
    "                ts.remove(s)\n",
    "print(len(new_translations[\"sux_to_en\"]), \"sux\")\n",
    "print(len(new_translations[\"akk_to_en\"]), \"akk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b324b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_translations():\n",
    "    for s_lang in src_langs:\n",
    "        for t_lang in tgt_langs:\n",
    "            st_key = f\"{s_lang}_to_{t_lang}\"\n",
    "            if st_key in new_translations:\n",
    "                translations = new_translations[st_key]\n",
    "                print(len(translations), f\"{st_key} translations\")\n",
    "                print([(x, translations[x]) for x in translations][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2b84c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91014 sux_to_en translations\n",
      "[('# e3 - = %a hi-a-t,u3-um # = %a ru-ub-bu-u2 # e3 - = %a e-ru-u2-um # e3 - = %a a-ma-((x))-rum # = %a szu-pu-u2-um # e3 - = %a sza-ka-kum # e3 - = %a za-qa2-nu-um # a-ra2 - |_a-du_| = %a t,e-mu-um # a-ra2 - = %a a-la-ak-tum # a-ra2 - = %a a-ru-ru#-u2#-um# # a-ra2 - |_a-x_|# = %a x-x-[...]', 'a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind'), ('# lah5 - [] = %a sza#-la#?-[lu-um] # lah5 - = %a a-la-kum# # lah5-lah5 - |_du-du-du-du_|# = %a bu-ub-bu-lum # gir5-gir5 - |_du_@s-_du_@s| = %a t,e3-bu-u2-um # gir5-gir5 - = %a ti-t,e3-bu-um # gir5-gir5 - = %a ha-la-pu-um # _du_@s-_du_@s - = %a as2#?-qu3-du-um # dun5-dun5 - |_bur2-bur2_|# = %a da#-ma-mu-um # du9-du9 - = %a da-ba#-bu-um # dun5-dun5 - = %a ma#-a-s,um', 'alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum'), ('# szuba2 - = %a bi#?-x-x?-mu#?-[x?] # szuba2 - = %a ra-am-kum# # %e szuba2 - = %a re#-ia-um # %e szuba2 - = %a (d)da-mu # nir7 - |_za_-gin2@g| = %a hu#-la-lum # zabalam2(ki) - |_za-musz3-ab_xESZ-_ki_|# = %a su2#?-ga-al;-lum#? # dida - |_bi-u2-sa_?|# = %a bi#-il-la#?-tum! # - |_bi-u2_| = %a hi-qum # uluszin3 - |_asz2-an_| = %a u2-lum-sze-in-um # imgaga3 - |_asz2-an_| = %a di#-zi-ip-tu-hi # (u2)uszusz!(_kal_) - |_u2-kal_|# = %a mi#-it,-rum', '... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...'), ('%a [...]-tam %a [x] x-di-in %a [x x] szar# ma-tim %a [tap?]-pu-tam [isz]-ta#-ka-an %a x-ri-im [x] x ka-bi-tum %a [x]-pi2-a asz-szum %a ha#-am-mu-ra-pi2 %a [x] ra#-ap-szum %a [x x]-ra-[...]-in# %a [...]-x-szu [...]-tam %a [...]-ur# %a [...]-x-szu %a [...] x', '... ... ... ... ... ... ... ...'), (\"'a3-nim-(d)da-gan lugal ma#-ri2#(ki) za#-x\", 'Anum-Dagan, king of Mari, ...'), ('($ blank line $)', 'a kind of reed mat'), ('($ erased $) ($ erased $) lugal-inim-gi-na dub-sar dumu lugal-nesag-e', 'scribe, son of Lugal-nesage.'), ('($ erased $) 2(asz@c) sila3 kasz sze ga2-udu-ur4 (d)inanna ur-(d)i7 1(asz@c) sila3 kasz sig15 ka id5 edin 2(disz@t) kasz dug szesz ensi2 unug(ki) e2#-zi#-[sza3?-gal2?]', 'erased; 2 sila3 barley beer for the sheepfold of Inanna; Ur-Id; 1 sila3 fine beer for the mouth of the canal of the steppe; 2 jugs of beer for the brother of the governor of Uruk, Ezishagal;'), ('($ erased $) nig2 u2-rum igi-ildu3-sze3@90 ($ erased $) 4(asz@c) sze gur abzu-ir-nun 5(asz@c)# sze 3(asz@c) 2(barig@c) sze 2(asz@c) 2(barig@c) sze 1(asz@c) _tug2_ gin2 1(asz@c) ninda-sur!(_mug_) 1(asz@c)# zabar 1(u@c) sila3 i3-szah2', 'erased property of Urum, to the account of Igildu; 90 gur barley, Abzu-irnun, 5 gur barley, 3 gur 2 barig barley, 2 gur 2 barig barley, 1 garment, shekels, 1 ninda-sur, 1 bronze, 10 sila3 lard,'), ('($ erasure $) 3(disz)-a-bi', 'total: 3.')]\n",
      "14170 akk_to_en translations\n",
      "[('& 5(disz) _sila3_ & 2(ban2) & 2(disz) _ku6-ba_ & 4(disz) be-el!-szu-nu', '5 sila3 2 ban2 2 kurru, 4 belshunu,'), (\"'ann'#rm 1\", \"'Ann'rm 1\"), (\"'ir'ab | tn 'szr\", \"'Irabu — n+20\"), ('($ erased line $) _sza3-ga-ni al-du10_ _inim-bi al-til_ _u4-kur2-sze3 lu2 lu2-ra_ _inim nu-um-ga2-ga2-a_ _mu_ (d)utu (d)marduk u3 ha-am-mu-ra-pi2 it-mu-u2 _igi_ ri-isz-(d)utu _dumu_ im-gur-akszak(ki) _igi_ be-el-szu-nu _dumu_ na-bi-i3-li2-szu _igi_ (d)utu-ha-s,ir _dumu_ si2-ia-tum _igi_ dingir-ra-bi u3 (d)utu-sza-tum _sanga_ (d)mar-tu _igi_ (d)utu-nu-ur2-bar-ra _sanga_ (d)utu _igi_ e-ri-ib-sin _igi_ (d)utu-s,il2-li2 _dumu_ _arad_-(d)mar-tu _igi_ szu-mi-er-s,e-tim _dub-sar_ _iti sig4-a_ _mu bu-ru-un-da_', 'The wording is finished. In the future, a person will not raise a claim concerning the name of Shamash, Marduk and Hammurapi. Before Rish-shamash, son of Imgurakshak; before Belshunu, son of Nabi-ilishu; before Shamash-hashir, son of Siyatum; before Ili-rabi and Shamash-shatum, priest of Shamash; before Shamash-nurbara, priest of Shamash; before Eribsin; before Shamash-shilli, son of Warad-Marduk; before Shumi-erishtim, the scribe. Month of brickwork, year of Burunda.'), ('($ erased line $) bar? pa ra a i-ta-na-szi-szi x um!-ma-sza', '... she ... her ...'), ('($lion$) ($table$) _kur (disz)an-szar2-du3-a man gal man_ dan-nu [...]', 'The lion of the land of Ashurbanipal, great king, strong king, ...'), ('(& blank space $) ki-ta _us2 ki-ta szu-na_', 'the lower side, the lower side, the access-way;'), ('((d)na-ra-am-(d)suen) _dingir_ a-ga-de3(ki) ur-da', 'Naram-Sin, god of Agade, the dog.'), ('((ka3-s,a-ri-im))', 'a kind of reed'), ('((m))ze-ri—_ka-dingir-ra#_-[_ki_ x x x]', 'Zeri-Babili ...')]\n"
     ]
    }
   ],
   "source": [
    "sample_translations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada5268c",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b41e0d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=model_revision, device=device)\n",
    "model_max_length = tokenizer.model_max_length\n",
    "model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcdfb82a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, revision=model_revision, max_length=tokenizer.model_max_length)\n",
    "model = model.to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0902776",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TranslationPipeline(model=model, tokenizer=tokenizer, batch_size=batch_size, device=device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b57bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Shalmaneser, great king, strong king, king of the universe,'}]\n",
      "[{'translation_text': 'He did it greatly.'}]\n"
     ]
    }
   ],
   "source": [
    "print(pipeline(\"translate Akkadian to English: 1(disz)(d)szul3-ma-nu-_sag man gal?_-u2 _man_ dan-nu _man kisz_\"))\n",
    "print(pipeline(\"translate Akkadian to English: ra-bi-isz e-pu-usz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c42721",
   "metadata": {},
   "source": [
    "## Load Transliterations to Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7bf11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corpi\n",
    "import cdli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b649ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'corpi' from '/home/fak/Projects/CuneiformTranslators/tools/corpi.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(corpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37377b14",
   "metadata": {},
   "source": [
    "## Load ORACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cce8c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cdli' from '/home/fak/Projects/CuneiformTranslators/tools/cdli.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cdli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af29ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/FrankDisk/oracc_zips'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracc_dir = os.path.abspath(f\"/Volumes/FrankDisk/oracc_zips\")\n",
    "# oracc_dir = os.path.abspath(f\"/home/fak/nn/Data/oracc_zips\")\n",
    "oracc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "381f9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracc_corpus = corpi.ORACC(oracc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86545b0",
   "metadata": {},
   "source": [
    "## Load CDLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3c0593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdli_corpus = corpi.CDLI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a7bb0",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "859790ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132155 unique publications\n"
     ]
    }
   ],
   "source": [
    "all_pubs = corpi.merge_corpus_pubs(\n",
    "    [\n",
    "        (\"oracc\", oracc_corpus.oracc_pubs.values()),\n",
    "        (\"cdli\", cdli_corpus.cdli_pubs.values())\n",
    "    ], src_langs)\n",
    "print(f\"Found {len(all_pubs)} unique publications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44291a7f",
   "metadata": {},
   "source": [
    "## Build Need Translation List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ceb6885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aba7776e2a44c06afe4aa7174df4859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sux max line length 612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c1f26338e24aa89cfc8c567e6a6eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akk max line length 849\n",
      "458557 sux needs translation\n",
      "195312 akk needs translation\n"
     ]
    }
   ],
   "source": [
    "def get_need_translations(src_lang, encoding=\"ascii\", tgt_lang=\"en\"):\n",
    "    srcs = set()\n",
    "\n",
    "    max_line_length = 0\n",
    "\n",
    "    for pub_id in tqdm(all_pubs.keys()):\n",
    "        pub = all_pubs[pub_id]\n",
    "        if pub.language != src_lang:\n",
    "            continue\n",
    "        corpus = pub.corpus\n",
    "        for a in pub.text_areas:\n",
    "            if (corpus == \"cdli\") and len(a.lines) > 0 and len(a.paragraphs) == 0:\n",
    "                a.lines_to_paragraphs(src_lang, tgt_lang)\n",
    "            paras = a.paragraphs_to_lines(src_lang, corpus)\n",
    "            for p in paras:\n",
    "                for si,ei,line in p:\n",
    "                    if len(line) > max_line_length:\n",
    "                        max_line_length = len(line)\n",
    "                    srcs.add(line)\n",
    "    print(src_lang, \"max line length\", max_line_length)\n",
    "    return srcs\n",
    "needs_translation = {     \n",
    "    \"sux\": get_need_translations(\"sux\"),\n",
    "    \"akk\": get_need_translations(\"akk\"),\n",
    "}\n",
    "print(len(needs_translation[\"sux\"]), \"sux needs translation\")\n",
    "print(len(needs_translation[\"akk\"]), \"akk needs translation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7b88abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[(disz)tat]-tan-nu _dumu_ sza2 (disz)ki-din-(d)60 A (disz)_e2-kur_-za-kir ina hu-ud lib3(*)#-[bi]-szu2# szi-isz-[szu-ru-u2] [sza2] u4#-mu ina _u4 7_-_kam2 gisz-szub-ba_-szu2 (lu2)_ku4 e2_(u2)-(tu2) _igi_ (d)_en-lil2_ (d)_idim_ (d)30 (d)#_utu_ (d)_iszkur_ (d)_amar-utu_ (d)na-na-a (d)_gaszan_-sza2(*)-_sag_ u _dingir_-_mesz e2_-szu2-nu gab-bi sza2 _iti_(us)-(su) kal _mu-an-na_ gu-uq-qa-ne2-e _u4-esz-esz_-_mesz_ u mim-ma gab-bi sza2 a-na szi-isz-szi-ru-u2 ina _u4 7_-_kam2 gisz-szub-ba_ [(lu2)]_ku4# e2_(u2)-(tu2)',\n",
       " '_u4_ szul3-ma _iti_ hi-du-tu2 _mu-an-na_ he2-gal2-li-sza2',\n",
       " 'a-na u4-mu s,a-a-tu2 it-ta-din _ku3-babbar_ a4 2 _ma-na szam2 gisz_(*)#-[_szub-ba_-_mesz mu_-_mesz til_-_mesz_ (disz)_nig2-sum-mu_-(d)60]',\n",
       " '_sa2-sag_ si-ma-hi-la-ne2',\n",
       " '[...] x pa-ni (lu2)_kur2 ta_ (iri)_e2_ x [...]',\n",
       " 'har-ra-nu i-na u4-me-szu-ma i-na qi2-bit (d)asz-szur _en_-ia (disz)nig2-du-(d)na-hu-un-du _lugal_ (kur)elam-ma(ki) 3(disz) _iti-mesz_ ul u2-mal-li-ma i-na u4-me la szi-im-ti-szu2 ur-ru-hi-isz im-tu-ut _egir_-szu2 (disz)um-man-me-na-nu la ra-asz2 t,e3-e-me u3 mil-ki _szesz_-szu2 dup-pu-us-su-u2 i-na _(gesz)gu-za_-szu2 u2-szib-ma i-na 8(disz)-e ger-ri-ia _egir_ (disz)szu-zu-bi is-se-hu-ma _dumu-mesz babila2(ki) gal5-la2-mesz_ lem-nu-ti _ka2-gal-mesz iri_',\n",
       " '[_igi_] (m)#_iti-ab_-a-a _igi_ (m)[x x x x x]',\n",
       " \"ina _ugu_ (m)(d)30—_lugal_—_pab_ sza tasz-pur-a-nin-ni _ta_(v) ma-as,-s,i-in(!) _a-kal_-_mesz_-szu ma-a'-du-u-ni u _ta_(v) _igi_-ku-nu ha(*)-rid(*)#-du-u-ni a-ta-a in-qu-ta ina _igi_-ia an-nu-ri ina _igi_-ia szu-u [x x] x#\",\n",
       " 'wa#-ah-szu-(sza)-na sze2-bi4-il5-ma [a]-pa2-ni-e-a li-ni-di2-i s,u2-ha-ru-a [a-di2-ni] isz-tu3 bu#-[ru]-usz?-ha#?-[tim] [la2] i-li-ku-nim [...]-a wa-ni-u2-tim [...] la2 i-na-szi2-u2 [...] da#-nu-tim [...] sza-ma-ma [...] ta# ki im [x] [...] x x [...] [...]',\n",
       " 'u-pisz-ma (m)dan-na#-[a] ina _sza 1_/2 _ma-na kug-ud_ il#-[qi]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(needs_translation[\"akk\"])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4c4b43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653,869 to translate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad7cd112ff846f4988d951e02e01e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/458557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b7633f0a1d49d3b2583a8ba404f0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156,893 left to translate\n"
     ]
    }
   ],
   "source": [
    "tgt_lang = \"en\"\n",
    "\n",
    "def get_translations():\n",
    "    todo = []\n",
    "    for src_lang in src_langs:\n",
    "        st_key = f\"{src_lang}_to_{tgt_lang}\"\n",
    "        news = new_translations[st_key]\n",
    "        # print(list(olds)[:10])\n",
    "        for src in tqdm(needs_translation[src_lang]):\n",
    "            if src not in news:\n",
    "                todo.append((src_lang, tgt_lang, src, f\"translate {languages.all_languages[src_lang]} to {languages.all_languages[tgt_lang]}: \" + src))\n",
    "    np.random.shuffle(todo)\n",
    "    for t in todo:\n",
    "        yield t\n",
    "\n",
    "num_need_translate = sum([len(x) for x in needs_translation.values()])\n",
    "print(f\"{num_need_translate:,} to translate\")\n",
    "to_translate = list(get_translations())\n",
    "print(f\"{len(to_translate):,} left to translate\")\n",
    "                \n",
    "def get_translations_gen():\n",
    "    for src_lang, tft_lang, s, q in tqdm(to_translate):\n",
    "        yield q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dacd9569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c24dd1153ff4ff0a6e2eeb45ae8314a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your input_length: 480 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 523 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 472 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 485 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 465 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 476 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 523 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 522 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 515 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 559 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 559 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 501 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 461 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 469 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 475 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 503 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 692 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 467 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 471 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 490 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 466 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 472 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 490 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 495 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 487 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 501 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 464 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 493 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 461 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 491 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    }
   ],
   "source": [
    "r = pipeline(get_translations_gen())\n",
    "for i, tr in enumerate(r):\n",
    "    src_lang, tft_lang, s, q = to_translate[i]\n",
    "    st_key = f\"{src_lang}_to_{tgt_lang}\"\n",
    "    translations = new_translations[st_key]\n",
    "    t = tr[0]['translation_text']\n",
    "    translations[s] = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c45ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458557 sux_to_en translations\n",
      "[('# e3 - = %a hi-a-t,u3-um # = %a ru-ub-bu-u2 # e3 - = %a e-ru-u2-um # e3 - = %a a-ma-((x))-rum # = %a szu-pu-u2-um # e3 - = %a sza-ka-kum # e3 - = %a za-qa2-nu-um # a-ra2 - |_a-du_| = %a t,e-mu-um # a-ra2 - = %a a-la-ak-tum # a-ra2 - = %a a-ru-ru#-u2#-um# # a-ra2 - |_a-x_|# = %a x-x-[...]', 'a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind of a kind'), ('# lah5 - [] = %a sza#-la#?-[lu-um] # lah5 - = %a a-la-kum# # lah5-lah5 - |_du-du-du-du_|# = %a bu-ub-bu-lum # gir5-gir5 - |_du_@s-_du_@s| = %a t,e3-bu-u2-um # gir5-gir5 - = %a ti-t,e3-bu-um # gir5-gir5 - = %a ha-la-pu-um # _du_@s-_du_@s - = %a as2#?-qu3-du-um # dun5-dun5 - |_bur2-bur2_|# = %a da#-ma-mu-um # du9-du9 - = %a da-ba#-bu-um # dun5-dun5 - = %a ma#-a-s,um', 'alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum alum'), ('# szuba2 - = %a bi#?-x-x?-mu#?-[x?] # szuba2 - = %a ra-am-kum# # %e szuba2 - = %a re#-ia-um # %e szuba2 - = %a (d)da-mu # nir7 - |_za_-gin2@g| = %a hu#-la-lum # zabalam2(ki) - |_za-musz3-ab_xESZ-_ki_|# = %a su2#?-ga-al;-lum#? # dida - |_bi-u2-sa_?|# = %a bi#-il-la#?-tum! # - |_bi-u2_| = %a hi-qum # uluszin3 - |_asz2-an_| = %a u2-lum-sze-in-um # imgaga3 - |_asz2-an_| = %a di#-zi-ip-tu-hi # (u2)uszusz!(_kal_) - |_u2-kal_|# = %a mi#-it,-rum', '... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...'), ('%a [...]-tam %a [x] x-di-in %a [x x] szar# ma-tim %a [tap?]-pu-tam [isz]-ta#-ka-an %a x-ri-im [x] x ka-bi-tum %a [x]-pi2-a asz-szum %a ha#-am-mu-ra-pi2 %a [x] ra#-ap-szum %a [x x]-ra-[...]-in# %a [...]-x-szu [...]-tam %a [...]-ur# %a [...]-x-szu %a [...] x', '... ... ... ... ... ... ... ...'), (\"'a3-nim-(d)da-gan lugal ma#-ri2#(ki) za#-x\", 'Anum-Dagan, king of Mari, ...'), ('($ blank line $)', 'a kind of reed mat'), ('($ erased $) ($ erased $) lugal-inim-gi-na dub-sar dumu lugal-nesag-e', 'scribe, son of Lugal-nesage.'), ('($ erased $) 2(asz@c) sila3 kasz sze ga2-udu-ur4 (d)inanna ur-(d)i7 1(asz@c) sila3 kasz sig15 ka id5 edin 2(disz@t) kasz dug szesz ensi2 unug(ki) e2#-zi#-[sza3?-gal2?]', 'erased; 2 sila3 barley beer for the sheepfold of Inanna; Ur-Id; 1 sila3 fine beer for the mouth of the canal of the steppe; 2 jugs of beer for the brother of the governor of Uruk, Ezishagal;'), ('($ erased $) nig2 u2-rum igi-ildu3-sze3@90 ($ erased $) 4(asz@c) sze gur abzu-ir-nun 5(asz@c)# sze 3(asz@c) 2(barig@c) sze 2(asz@c) 2(barig@c) sze 1(asz@c) _tug2_ gin2 1(asz@c) ninda-sur!(_mug_) 1(asz@c)# zabar 1(u@c) sila3 i3-szah2', 'erased property of Urum, to the account of Igildu; 90 gur barley, Abzu-irnun, 5 gur barley, 3 gur 2 barig barley, 2 gur 2 barig barley, 1 garment, shekels, 1 ninda-sur, 1 bronze, 10 sila3 lard,'), ('($ erasure $) 3(disz)-a-bi', 'total: 3.')]\n",
      "195312 akk_to_en translations\n",
      "[('& 5(disz) _sila3_ & 2(ban2) & 2(disz) _ku6-ba_ & 4(disz) be-el!-szu-nu', '5 sila3 2 ban2 2 kurru, 4 belshunu,'), (\"'ann'#rm 1\", \"'Ann'rm 1\"), (\"'ir'ab | tn 'szr\", \"'Irabu — n+20\"), ('($ erased line $) _sza3-ga-ni al-du10_ _inim-bi al-til_ _u4-kur2-sze3 lu2 lu2-ra_ _inim nu-um-ga2-ga2-a_ _mu_ (d)utu (d)marduk u3 ha-am-mu-ra-pi2 it-mu-u2 _igi_ ri-isz-(d)utu _dumu_ im-gur-akszak(ki) _igi_ be-el-szu-nu _dumu_ na-bi-i3-li2-szu _igi_ (d)utu-ha-s,ir _dumu_ si2-ia-tum _igi_ dingir-ra-bi u3 (d)utu-sza-tum _sanga_ (d)mar-tu _igi_ (d)utu-nu-ur2-bar-ra _sanga_ (d)utu _igi_ e-ri-ib-sin _igi_ (d)utu-s,il2-li2 _dumu_ _arad_-(d)mar-tu _igi_ szu-mi-er-s,e-tim _dub-sar_ _iti sig4-a_ _mu bu-ru-un-da_', 'The wording is finished. In the future, a person will not raise a claim concerning the name of Shamash, Marduk and Hammurapi. Before Rish-shamash, son of Imgurakshak; before Belshunu, son of Nabi-ilishu; before Shamash-hashir, son of Siyatum; before Ili-rabi and Shamash-shatum, priest of Shamash; before Shamash-nurbara, priest of Shamash; before Eribsin; before Shamash-shilli, son of Warad-Marduk; before Shumi-erishtim, the scribe. Month of brickwork, year of Burunda.'), ('($ erased line $) bar? pa ra a i-ta-na-szi-szi x um!-ma-sza', '... she ... her ...'), ('($lion$) ($table$) _kur (disz)an-szar2-du3-a man gal man_ dan-nu [...]', 'The lion of the land of Ashurbanipal, great king, strong king, ...'), ('(& blank space $) ki-ta _us2 ki-ta szu-na_', 'the lower side, the lower side, the access-way;'), ('((d)na-ra-am-(d)suen) _dingir_ a-ga-de3(ki) ur-da', 'Naram-Sin, god of Agade, the dog.'), ('((ka3-s,a-ri-im))', 'a kind of reed'), ('((m))ze-ri—_ka-dingir-ra#_-[_ki_ x x x]', 'Zeri-Babili ...')]\n"
     ]
    }
   ],
   "source": [
    "sample_translations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c5dec",
   "metadata": {},
   "source": [
    "## Save the Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e19455b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_translations(f):\n",
    "    f.write(\"{\\n\")\n",
    "    f.write(f\"\\\"model_id\\\":\\\"{model_id}\\\",\\n\")\n",
    "    f.write(f\"\\\"model_revision\\\":\\\"{model_revision}\\\"\")\n",
    "    for st_key in sorted([x for x in new_translations if not x.startswith(\"model_\")]):\n",
    "        f.write(f\",\\n\\\"{st_key}\\\":{{\\n\")\n",
    "        translations = new_translations[st_key]\n",
    "        head = \"\"\n",
    "        for s in sorted(list(translations.keys())):\n",
    "            f.write(head)\n",
    "            f.write(json.dumps(s))\n",
    "            f.write(\": \")\n",
    "            f.write(json.dumps(translations[s]))\n",
    "            head = \",\\n\"\n",
    "        f.write(\"}\")\n",
    "    f.write(\"}\\n\")\n",
    "    \n",
    "# write_translations(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00f5c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_json_path, \"wt\") as f:\n",
    "    write_translations(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2e4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f0c3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def compress(zip_name, file_to_zip):\n",
    "    if os.path.exists(zip_name):\n",
    "        os.unlink(zip_name)\n",
    "    # Create a new zip file and add files to it\n",
    "    with zipfile.ZipFile(zip_name, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.write(file_to_zip)\n",
    "    os.unlink(file_to_zip)\n",
    "\n",
    "compress('../data/ml_translations.zip', '../data/ml_translations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f514837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 92988\r\n",
      "drwxrwxr-x  2 fak fak     4096 Jun  9 05:55 .\r\n",
      "drwxrwxr-x 10 fak fak     4096 Jun  1 13:42 ..\r\n",
      "-rw-rw-r--  1 fak fak 24652099 Jun  5 11:54 cdli_pubs.zip\r\n",
      "-rw-rw-r--  1 fak fak    56450 Jul 25  2022 dataset_index.json\r\n",
      "-rw-rw-r--  1 fak fak 30341325 Jun  9 05:55 ml_translations.zip\r\n",
      "-rw-rw-r--  1 fak fak 13153368 Jun  6 12:43 oracc_pubs.zip\r\n",
      "-rw-rw-r--  1 fak fak 22458763 Jun  6 12:43 translations_akk_to_en.jsonl\r\n",
      "-rw-rw-r--  1 fak fak  4537536 Jun  6 12:43 translations_sux_to_en.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb261ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c7d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
