{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Translator\n",
    "\n",
    "Based on: https://huggingface.co/docs/transformers/tasks/translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, datetime\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import TranslationPipeline\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdli\n",
    "import languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finetune_model_id(model_id):\n",
    "    model_dir = f\"../results/{model_id}\"\n",
    "    checkpoints = [(os.path.abspath(x), int(os.path.split(x)[1].split(\"-\")[1])) for x in glob.glob(f\"{model_dir}/checkpoint-*\")]\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: x[1])[-1]\n",
    "    return checkpoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"TrainTranslator.ipynb\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "source_langs = set([\"akk\"])\n",
    "\n",
    "# target_langs = set([\"en\", \"it\", \"es\", \"fr\", \"de\"])\n",
    "target_langs = set([\"en\"])\n",
    "\n",
    "base_model_id = \"t5-base\"\n",
    "finetune_model_id = None\n",
    "# finetune_model_id = get_finetune_model_id(\"t5-base-p-akksux-en-20220722-173018\")\n",
    "\n",
    "model_max_length = 512\n",
    "batch_size = 8 if os.path.basename(base_model_id).startswith(\"t5-base\") else 128\n",
    "\n",
    "num_train_epochs = 30\n",
    "\n",
    "is_bi = False\n",
    "use_paragraphs = True\n",
    "use_lines = True\n",
    "is_finetune = finetune_model_id is not None and len(finetune_model_id) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t5-base-p-l-akk-en-20220725-224830'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_id = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "flags = \"\"\n",
    "suffix = \"\"\n",
    "if is_bi:\n",
    "    flags += \"-bi\"\n",
    "if use_paragraphs:\n",
    "    flags += \"-p\"\n",
    "if use_lines:\n",
    "    flags += \"-l\"\n",
    "if is_finetune:\n",
    "    flags += \"-f\"\n",
    "    suffix += f\"-{os.path.basename(os.path.split(finetune_model_id)[0])}-{os.path.basename(finetune_model_id)}\"\n",
    "model_id = f\"{os.path.basename(base_model_id)}{flags}-{''.join(sorted(list(source_langs)))}-{''.join(sorted(list(target_langs)))}-{date_id}{suffix}\"\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, <torch.cuda.device at 0x7fc7951fed10>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_cuda = torch.cuda.is_available()\n",
    "device = torch.cuda.device(0) if has_cuda else \"cpu\"\n",
    "has_cuda, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 25 22:48:30 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 30%   50C    P8    31W / 350W |    168MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A       971      G   /usr/lib/xorg/Xorg                120MiB |\r\n",
      "|    0   N/A  N/A      1236      G   ...ome-remote-desktop-daemon        4MiB |\r\n",
      "|    0   N/A  N/A      1272      G   /usr/bin/gnome-shell               23MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_src_chars_per_token = 1.8713256996006793\n",
    "avg_tgt_chars_per_token = 2.577806274115267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate Sumerian to Spanish: '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prefix(src_lang, tgt_lang):\n",
    "    s = languages.all_languages[src_lang]\n",
    "    t = languages.all_languages[tgt_lang]\n",
    "    return f\"translate {s} to {t}: \"\n",
    "    \n",
    "get_prefix(\"suxts\", \"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/cdli-gh/data/raw/master/cdliatf_unblocked.atf\n",
      "Parsing atf\n"
     ]
    }
   ],
   "source": [
    "publications = cdli.get_atf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134712, 'publications')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(publications), \"publications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False ''\n",
      "False ' '\n",
      "False 'xx xxx x'\n",
      "False '.. . .. '\n",
      "True 'Hi'\n"
     ]
    }
   ],
   "source": [
    "def target_ok(target_text):\n",
    "    if len(target_text) == 0:\n",
    "        return False\n",
    "    if len(set(target_text.replace(\" \", \"\"))) < 2:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "def test_target_ok(text):\n",
    "    ok = target_ok(text)\n",
    "    print(ok, repr(text))\n",
    "    \n",
    "test_target_ok(\"\")\n",
    "test_target_ok(\" \")\n",
    "test_target_ok(\"xx xxx x\")\n",
    "test_target_ok(\".. . .. \")\n",
    "test_target_ok(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wmax_num_tokens = model_max_length - 192\n",
    "\n",
    "def wrap_paragraph(paragraph, lines, src_lang, tgt_lang):\n",
    "    ptag, pline_start_index, pline_end_index = paragraph\n",
    "    wline_ranges = []\n",
    "    wline_tok_len = 0.0\n",
    "    \n",
    "    def start_new_line(pline_index):\n",
    "#         print(\"start\", pline_index)\n",
    "        wline_ranges.append((pline_index, pline_index + 1))\n",
    "        \n",
    "    def append_line(pline_index):\n",
    "#         print(\"append\", pline_index)\n",
    "        r = wline_ranges[-1]\n",
    "        if r[1] == pline_index:\n",
    "            wline_ranges[-1] = (r[0], r[1] + 1)\n",
    "        else:\n",
    "            print(f\"Missing line: got {pline_index}, expected {r[1]}: {wline_ranges}\")\n",
    "\n",
    "    for pline_index in range(pline_start_index, pline_end_index):\n",
    "        pline_num_toks = len(lines[pline_index].text) / avg_src_chars_per_token + 1.0\n",
    "        if len(wline_ranges) == 0 or (wline_tok_len + pline_num_toks > wmax_num_tokens):\n",
    "            start_new_line(pline_index)\n",
    "            wline_tok_len = 0.0\n",
    "        else:\n",
    "            append_line(pline_index)\n",
    "        wline_tok_len += pline_num_toks\n",
    "    return wline_ranges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['akk', 'sux'])\n"
     ]
    }
   ],
   "source": [
    "dataset_index = json.load(open(\"../data/dataset_index.json\", \"rt\"))\n",
    "print(dataset_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870 akk train\n",
      "108 akk test\n",
      "3753 sux train\n",
      "396 sux test\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_index[\"akk\"][\"train\"]), \"akk train\")\n",
    "print(len(dataset_index[\"akk\"][\"test\"]), \"akk test\")\n",
    "print(len(dataset_index[\"sux\"][\"train\"]), \"sux train\")\n",
    "print(len(dataset_index[\"sux\"][\"test\"]), \"sux test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing akk to en\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fdc60da42f4596af91e7dcccb1919b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing akk to en\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a20c9fcc4e435298f08c5a75cb0428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16754 train\n",
      "1728 test\n"
     ]
    }
   ],
   "source": [
    "def get_pubs_targets(dataset):\n",
    "    new_sourceandtargets = []\n",
    "\n",
    "    added_sources = set()\n",
    "\n",
    "    def add_line_ranges(area, b, e):\n",
    "    #                     print(\"-\"*50)\n",
    "        ls = \" \".join([x.text for x in area.lines[b:e]])\n",
    "        ls = \" \".join(ls.split(\" \"))\n",
    "        prefixed_ls = st_prefix + ls\n",
    "        if prefixed_ls in added_sources:\n",
    "            return\n",
    "        lt = \" \".join([(x.languages[t] if t in x.languages else \"\") for x in area.lines[b:e]])\n",
    "        lt = \" \".join(lt.split(\" \"))\n",
    "        lt = languages.replace_unsupported(lt)\n",
    "        if not target_ok(lt):\n",
    "            return\n",
    "    #                     print(ls)\n",
    "    #                     print(lt)\n",
    "        added_sources.add(prefixed_ls)\n",
    "        new_sourceandtargets.append((prefixed_ls, lt))\n",
    "        if is_bi:\n",
    "            new_sourceandtargets.append((ts_prefix + lt, ls))\n",
    "\n",
    "    for s in source_langs:\n",
    "        pub_index = dataset_index[s][dataset]\n",
    "        for t in target_langs:\n",
    "            print(\"Preparing\", s, \"to\", t)            \n",
    "            st_prefix = get_prefix(s, t)\n",
    "            ts_prefix = get_prefix(t, s)\n",
    "            for pub in tqdm([p for p in publications if p.language==s and p.id in pub_index]):\n",
    "                for area in pub.text_areas:\n",
    "                    if not any(x for x in area.lines if t in x.languages):\n",
    "                        continue\n",
    "                    if use_paragraphs:\n",
    "                        paragraphs = area.lines_to_paragraphs(s)\n",
    "                        line_ranges = []                \n",
    "                        for p in paragraphs:                    \n",
    "                            wlines = wrap_paragraph(p, area.lines, s, t)\n",
    "                            line_ranges.extend(wlines)\n",
    "        #                 print(\"=\"*50, len(area.lines))\n",
    "                        for b, e in line_ranges:\n",
    "                            add_line_ranges(area, b, e)\n",
    "                    if use_lines:\n",
    "                        for i, _ in enumerate(area.lines):\n",
    "                            add_line_ranges(area, i, i + 1)\n",
    "    random.shuffle(new_sourceandtargets)\n",
    "    return Dataset.from_dict({\"source\": [x[0] for x in new_sourceandtargets], \"target\": [x[1] for x in new_sourceandtargets]})\n",
    "\n",
    "train_dataset = get_pubs_targets(\"train\")\n",
    "test_dataset = get_pubs_targets(\"test\")\n",
    "print(len(train_dataset), \"train\")\n",
    "print(len(test_dataset), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 16754\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 1728\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': ['translate Akkadian to English: i-szar-li-im',\n",
       "  'translate Akkadian to English: sza-ar-ka-szu-um',\n",
       "  'translate Akkadian to English: [{d}suen]',\n",
       "  'translate Akkadian to English: sza a-ah na-ri-im',\n",
       "  'translate Akkadian to English: s,al-lam {d}utu _en zimbir{ki} a-szib-bi e2-babbar-ra s,al-lam {d}utu _en zimbir{ki} a-szib-bi e2-babbar-ra',\n",
       "  'translate Akkadian to English: su4-nu-ti',\n",
       "  'translate Akkadian to English: [u3 {d}inanna?]',\n",
       "  'translate Akkadian to English: _kur_ asz-ma ki-sir-ti',\n",
       "  'translate Akkadian to English: {d}da-gan',\n",
       "  'translate Akkadian to English: [AN]-nu-ba-ni-ni',\n",
       "  'translate Akkadian to English: _1(u) sze gur_',\n",
       "  'translate Akkadian to English: ki-ma sza-ma?!',\n",
       "  'translate Akkadian to English: a-na ti-li u3 ka-ar-mi',\n",
       "  'translate Akkadian to English: [ha]-a-ra-am _dumu_ a-ta-ni-im',\n",
       "  'translate Akkadian to English: i-na ma-asz-ha-li-im ta-sza-ah-ha-al',\n",
       "  'translate Akkadian to English: isz-ku8-na-ma',\n",
       "  'translate Akkadian to English: wa-ar-ki t,up-pi2-ia an-ne2-e-im#',\n",
       "  'translate Akkadian to English: um-ma wa-ak-lum2-ma a-na# [ka3]-ri-im ka3-ni-isz{ki} qi2-bi2#-ma# a-lu-um [di2]-nam# _igi_ 2(disz) _gesz-gag-en [gal?_ i]-na ha-am-ri-im [i-di2-in]-ma# 5(disz) a-wi-li [...] x',\n",
       "  'translate Akkadian to English: in |A.HA|{ki}',\n",
       "  'translate Akkadian to English: sza _5(u) mu-mesz kur_ al-zi',\n",
       "  'translate Akkadian to English: pa-la-am ar-ka-am',\n",
       "  'translate Akkadian to English: du-ra-ni-szu-nu iq-qu2-ur-ma',\n",
       "  'translate Akkadian to English: [a-na s,e]-er sa-mu-{d}iszkur [asz-pu-ur] u3 sza-pi2-il-ti s,a-bi-im [sza i-na] li-bi ma-a-tim isz7-ta-ah-hu',\n",
       "  'translate Akkadian to English: lu u3-um-mi-su2',\n",
       "  'translate Akkadian to English: ma-tum szi-i ki-ma ma-a-at szu-ba-ar#-tim#',\n",
       "  'translate Akkadian to English: sza a-bu-u2 ha-na ka-lu-szu-nu i-pu-szu-szu',\n",
       "  'translate Akkadian to English: a-na nu-ur2-{d}suen',\n",
       "  'translate Akkadian to English: il-li-ik-ma',\n",
       "  'translate Akkadian to English: {d}inanna _sag_-ti _dingir-mesz_ be-let te-sze-e',\n",
       "  'translate Akkadian to English: a-na szi-ir {d}utu',\n",
       "  'translate Akkadian to English: in _agar4_-ri2',\n",
       "  'translate Akkadian to English: a-pil2-ku-bi',\n",
       "  'translate Akkadian to English: wa-ar-ki-szu u3-sza-li-ik-szi',\n",
       "  'translate Akkadian to English: _a-sza3_ nam-ra-s,i lu-u2 ab-bal-kit',\n",
       "  'translate Akkadian to English: i-tur2-{d}utu',\n",
       "  'translate Akkadian to English: isz-ku-nu-szu a-na li-bi ma-ti-szu [i]-tu-ru sa-mu-{d}iszkur isz-pu-ra-am-ma [a]-na s,a-bi-im sza it-ti-ia il-li-kam [t,e4]-ma#-am sza t,a3-ra-di-im',\n",
       "  'translate Akkadian to English: _dub-sar_',\n",
       "  'translate Akkadian to English: ki-i pi-i',\n",
       "  'translate Akkadian to English: da-num2',\n",
       "  'translate Akkadian to English: sza {d}na3-ibila-uri3',\n",
       "  'translate Akkadian to English: e-pir6-mu-pi5',\n",
       "  'translate Akkadian to English: su4-a',\n",
       "  'translate Akkadian to English: [a]-na ia-as2-ma-ah-{d}[iszkur]',\n",
       "  'translate Akkadian to English: ma-ri2{ki}',\n",
       "  'translate Akkadian to English: li-il-[qu3-ta2]',\n",
       "  'translate Akkadian to English: _kur_-i ra-bu-tim la ik-szu-du',\n",
       "  'translate Akkadian to English: _8(asz@c) sze gur sag-gal2_',\n",
       "  'translate Akkadian to English: ki-tin-nu _4(u) ma-na ki-la2_-szu2-nu 1(disz)-en {gada}hu-la-nu',\n",
       "  'translate Akkadian to English: i-na s,e-er s,u2-uh2-ri-im',\n",
       "  'translate Akkadian to English: {lu2}mu-kin-nu {disz}{d}en-ba-sza2',\n",
       "  'translate Akkadian to English: _{lu2}azlag2_ i-ip-al-szu asz-szum e2-a be-el ne2-em-si2-im sza u2-ba-la-t,u3#-[ni?]',\n",
       "  'translate Akkadian to English: [_sipa_] mu-t,i-ib',\n",
       "  'translate Akkadian to English: _sanga_ {d}nin-in-si-na',\n",
       "  'translate Akkadian to English: a-na u4-mi da-ru-tim',\n",
       "  'translate Akkadian to English: i-na ne-pa-ri-im sza _nig2-szu_ e-tel-pi4-lugal {disz}ia-as,-s,u2-ur-{d}iszkur',\n",
       "  'translate Akkadian to English: _lugal_ si-mu-ri-im{ki}',\n",
       "  'translate Akkadian to English: qa2 szi-id-dim ta-la-aq-qa-at',\n",
       "  'translate Akkadian to English: _igi_ lu2-{d}iszkur-ra',\n",
       "  'translate Akkadian to English: na-ra-am-{d}suen',\n",
       "  'translate Akkadian to English: _dumu_ [...]',\n",
       "  'translate Akkadian to English: asz-ra-nu-um-ma-a a-na ga-am-ri-im-ma',\n",
       "  'translate Akkadian to English: i-na zi-ib-na-tim{ki} wa-asz-ba-at',\n",
       "  'translate Akkadian to English: suen-lugal udu-mes _sa12-du5_ AN-en-mah2 an _dam_ udu-mes {d}inanna-ki-ag2 EN MU DU A TAK4 UDU',\n",
       "  'translate Akkadian to English: i-na tu-ut-tu-ul-ma{ki}',\n",
       "  'translate Akkadian to English: {d}iszkur',\n",
       "  'translate Akkadian to English: _sig4 al-ur3-ra_',\n",
       "  'translate Akkadian to English: _a_-szu2 sza2 {disz}zalag2-e-a _a_ {disz}ir-a-ni',\n",
       "  'translate Akkadian to English: _dumu_ AN [...]',\n",
       "  'translate Akkadian to English: {lu2}tug2-babbar babilax(|DIN.TIR|)#{ki}',\n",
       "  'translate Akkadian to English: u2-um-mi-su',\n",
       "  'translate Akkadian to English: _inim-ta_ {d}ri-im-{d}suen-{d}utu-szi-ni',\n",
       "  'translate Akkadian to English: mu-re-ti na-re-e na-bi szu-mi',\n",
       "  'translate Akkadian to English: {disz}{d}suen-ma-gir _ka-ninda_',\n",
       "  'translate Akkadian to English: u-ma-li-su-nu',\n",
       "  'translate Akkadian to English: _dumu_ szu-su2-en6 _dumu_ bu-za-zu',\n",
       "  'translate Akkadian to English: ma-asz-sza-ar-ti ka-ri-im sza iri{ki}-ARAD2-{d}suen _szu-ti-a_ ne-ru-ba-a-tim sza ki-sza-ad _i7 idigna-an-ta_ _inim-ta_ {d}ri-im-{d}suen-{d}utu-szi-ni _giri3_ im-me-er-dingir _dumu e2-gal_ u3 za-ku-re-e-lum _kiszib3-ba-ne-ne i-ib2-ra_ szum-ma _e2-gal_-lum ni-ik-ka-sa3-am la im-ta-ha-ar',\n",
       "  'translate Akkadian to English: [sza {d}suen]-mu-ba-li2-it,',\n",
       "  'translate Akkadian to English: isz-pu-uk',\n",
       "  'translate Akkadian to English: i3-nu',\n",
       "  'translate Akkadian to English: i-na ni-qi2 be-li2-ia'],\n",
       " 'target': ['Ishar-Lim,',\n",
       "  'has been presented,',\n",
       "  'Sîn,',\n",
       "  '\"which is on the bank of the river\"',\n",
       "  'Image of Shamash, lord of Sippar, dwelling in Ebabbar. Image of Shamash, lord of Sippar, dwelling in Ebabbar.',\n",
       "  'those',\n",
       "  'and Ishtar,',\n",
       "  'of Assyria: facing (brick)',\n",
       "  'Dagan,',\n",
       "  'Anubanini,',\n",
       "  '10 gur of barley,',\n",
       "  'Like (unwanted) rain',\n",
       "  'into ruined mounds and ruin heaps',\n",
       "  'a donkey foal, the young of a donkey mare,',\n",
       "  'You will strain it through a sieve.',\n",
       "  'he engaged, and',\n",
       "  'after this my tablet,',\n",
       "  'Thus “Foreman,” to Karum-Kanesh: speak! The city a verdict, before two shugarria’um-symbols, in the sacred precinct gave; five men ..., ...,',\n",
       "  'in Tiwa',\n",
       "  'who for 50 years the land of Alzi',\n",
       "  'a long reign',\n",
       "  'Their walls he broke down, and',\n",
       "  'to Samu-Addu I sent; further, the remainder of the troops who in the heart of the land had dispersed;',\n",
       "  'I set next to it.',\n",
       "  'that land like the land of Shubartu',\n",
       "  'which all the elders of Hana had built,',\n",
       "  '\"to Nur-Sin,',\n",
       "  'he went, and',\n",
       "  'Ishtar, first of the gods, lady of chaos,',\n",
       "  'to the well-being of Shamash',\n",
       "  'in the field',\n",
       "  'Apil-Kubi,',\n",
       "  'and made it follow after him.',\n",
       "  'difficult terrain, I crossed,',\n",
       "  'Itur-Shamash,',\n",
       "  'had set, to the heart of the land returned; Samu-Addu wrote me, and to the troops who with me came, report of dispatch,',\n",
       "  'scribe,',\n",
       "  'According to the mouth',\n",
       "  'the mighty',\n",
       "  'of Nabopolassar,',\n",
       "  'Epir-mupi,',\n",
       "  'this',\n",
       "  'To Yasmah-Addu',\n",
       "  'of Mari,',\n",
       "  'may they both pluck up.',\n",
       "  'the great mountains, had he ever reached',\n",
       "  '8 saggal-gur barley,',\n",
       "  'made of kitinnû-linen, their weight 40 minas, 1 linen hullanu-wrap,',\n",
       "  'to young',\n",
       "  'witnesses: Bel-iqisha,',\n",
       "  'The fuller answers him: “By Ea, lord of the washbowl, who gives me life!',\n",
       "  'the shepherd who pleases',\n",
       "  'sanga priest of the goddess Ninisina,',\n",
       "  'forever,',\n",
       "  'in the jail for the goods of Etel-pî-sharrim Yashshur-Addu',\n",
       "  'king of Simurrum,',\n",
       "  'You will pick up the thread of the (shorter) border.',\n",
       "  'before Awil-adad;',\n",
       "  'Naram-Sîn',\n",
       "  'son of ...',\n",
       "  'there finally',\n",
       "  'in Zibnatum do you live?',\n",
       "  '(To the god) Suen-lugal, Udumes, cheif surveyor of AN-enmah, for the wife of Udumes, Inanna-ki’ag, ...',\n",
       "  'In Tuttul',\n",
       "  'Adad',\n",
       "  'of a baked brick',\n",
       "  'son of Nureya, descendant of Ir’ani;',\n",
       "  'son of ...',\n",
       "  'Pushaya; in Babylon,',\n",
       "  'he laid next to it.',\n",
       "  'at the order of Rim-Sin-Shamshini;',\n",
       "  'who erects stelas bearing (his) name,',\n",
       "  'Sîn-magir, responsible (of the temple) for the bread;',\n",
       "  'he filled them (their bodies),',\n",
       "  \"son of Shu-Su'en, son of Buzazu\",\n",
       "  'expenditures at the quay of Al-warad-Sin, a receipt of a pledge(?) at the bank of the Tigris river at the order of Rim-Sin-Shamshini; via Immer-ili, son of the palace, and Zakur-elum, they rolled their seals; if the palace the account does not accept,',\n",
       "  'that of Sîn-muballiț',\n",
       "  '(a burial mound) he heaped up.',\n",
       "  'when',\n",
       "  'in the offerings of my lord']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1120:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 16754\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 1728\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 1728\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tests = translations[\"test\"]\n",
    "original_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function should_test at 0x7fc61271eb90> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['translate Akkadian to ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae2924405214e47a599b860685d8a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 1728\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_starts = [f\"translate {languages.all_languages[s]} to \" for s in source_langs]\n",
    "print(test_starts)\n",
    "\n",
    "def should_test(t):\n",
    "    return any(t[\"source\"].startswith(s) for s in test_starts)\n",
    "\n",
    "translations[\"test\"] = original_tests.filter(should_test)\n",
    "translations[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, model_max_length=model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad <pad> 0\n",
      "eos </s> 1\n",
      "unk <unk> 2\n"
     ]
    }
   ],
   "source": [
    "print(\"pad\", tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(\"eos\", tokenizer.eos_token, tokenizer.eos_token_id)\n",
    "print(\"unk\", tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c899f7915f2e47469c15e37d79895c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13959, 4823, 1258, 8603, 12, 1566, 10, 3, 2, 26, 2, 7, 76, 35, 18, 76, 357, 4663, 18, 7, 15, 7412, 15, 40, 18, 40, 23, 3, 834, 26, 440, 76, 4663, 834, 206, 18, 450, 7412, 2, 26, 2, 76, 17, 76, 1]\n",
      "[180, 3851, 18, 302, 7999, 6, 520, 13, 10037, 18, 134, 1483, 3198, 6, 1]\n",
      "31 15 2.066666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99849b955144c1aa2391ec1b9502e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 16754\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1728\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc = 0\n",
    "sum_src_chars_per_token = 0.0\n",
    "num_src_chars_per_token = 0\n",
    "sum_tgt_chars_per_token = 0.0\n",
    "num_tgt_chars_per_token = 0\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    global ccc, sum_src_chars_per_token, sum_tgt_chars_per_token, num_src_chars_per_token, num_tgt_chars_per_token\n",
    "#     print(examples)\n",
    "    inputs = [example for example in examples[\"source\"]]\n",
    "    targets = [example for example in examples[\"target\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=model_max_length, truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=model_max_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    nexamples = len(inputs)\n",
    "    for i in range(nexamples):\n",
    "        nchar = len(inputs[i])\n",
    "        ntoks = len(model_inputs[\"input_ids\"][i])\n",
    "        if ntoks > 0:\n",
    "            sum_src_chars_per_token += nchar / ntoks\n",
    "            num_src_chars_per_token += 1\n",
    "        nchar = len(targets[i])\n",
    "        ntoks = len(model_inputs[\"labels\"][i])\n",
    "        if ntoks > 0:\n",
    "            sum_tgt_chars_per_token += nchar / ntoks\n",
    "            num_tgt_chars_per_token += 1\n",
    "    \n",
    "    ccc += 1\n",
    "    if ccc == 1:\n",
    "        print(model_inputs[\"input_ids\"][0])\n",
    "        print(model_inputs[\"labels\"][0])\n",
    "        nchar = len(targets[0])\n",
    "        ntoks = len(model_inputs[\"labels\"][0])\n",
    "        print(nchar, ntoks, nchar / ntoks)\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_translations = translations.map(preprocess_function, batched=True)\n",
    "tokenized_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_src_chars_per_token = 1.9792946054117202\n",
      "avg_tgt_chars_per_token = 2.77862621552965\n"
     ]
    }
   ],
   "source": [
    "avg_src_chars_per_token = sum_src_chars_per_token / num_src_chars_per_token\n",
    "avg_tgt_chars_per_token = sum_tgt_chars_per_token / num_tgt_chars_per_token\n",
    "print(\"avg_src_chars_per_token\", \"=\", avg_src_chars_per_token)\n",
    "print(\"avg_tgt_chars_per_token\", \"=\", avg_tgt_chars_per_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 16754\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1728\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_translations[\"train\"] = tokenized_translations[\"train\"].remove_columns([\"source\", \"target\"])\n",
    "tokenized_translations[\"test\"] = tokenized_translations[\"test\"].remove_columns([\"source\", \"target\"])\n",
    "tokenized_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510, 305)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_max_length = max([len(x[\"input_ids\"]) for x in tokenized_translations[\"train\"]])\n",
    "target_max_length = max([len(x[\"labels\"]) for x in tokenized_translations[\"train\"]])\n",
    "source_max_length, target_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[180, 3851, 18, 302, 7999, 6, 520, 13, 10037, 18]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_translations[\"train\"][0][\"labels\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(finetune_model_id if is_finetune else base_model_id, \n",
    "                                              max_length=model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-base\",\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 3072,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"max_length\": 512,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.19.4\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "# data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"../results/{model_id}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2*2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    fp16=has_cuda,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_translations[\"train\"],\n",
    "    eval_dataset=tokenized_translations[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fak/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 16754\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62850\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpraeclarum\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/fak/Projects/CuneiformTranslators/tools/wandb/run-20220725_224903-gu0dd7hv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/praeclarum/huggingface/runs/gu0dd7hv\" target=\"_blank\">../results/t5-base-p-l-akk-en-20220725-224830</a></strong> to <a href=\"https://wandb.ai/praeclarum/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62850' max='62850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62850/62850 2:17:12, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.037300</td>\n",
       "      <td>2.579712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.605100</td>\n",
       "      <td>2.298664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>2.154751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.170400</td>\n",
       "      <td>2.061167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.992100</td>\n",
       "      <td>2.003892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.886200</td>\n",
       "      <td>1.963448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.771900</td>\n",
       "      <td>1.937001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.698800</td>\n",
       "      <td>1.906494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.567300</td>\n",
       "      <td>1.905355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.523900</td>\n",
       "      <td>1.896165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.466300</td>\n",
       "      <td>1.881265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.407400</td>\n",
       "      <td>1.884579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.354200</td>\n",
       "      <td>1.884051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.316300</td>\n",
       "      <td>1.901947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.242300</td>\n",
       "      <td>1.899138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.208200</td>\n",
       "      <td>1.901327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.154800</td>\n",
       "      <td>1.913847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.131400</td>\n",
       "      <td>1.917312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.095400</td>\n",
       "      <td>1.926056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.080300</td>\n",
       "      <td>1.936084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.038900</td>\n",
       "      <td>1.942162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.008200</td>\n",
       "      <td>1.964417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.011700</td>\n",
       "      <td>1.954913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.989100</td>\n",
       "      <td>1.963071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.956200</td>\n",
       "      <td>1.970985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.951400</td>\n",
       "      <td>1.979376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.936800</td>\n",
       "      <td>1.986311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.937400</td>\n",
       "      <td>1.986611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>1.987020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.917900</td>\n",
       "      <td>1.990718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-2500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-4500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-6500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-8500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-13500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-17500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-18500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-21500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-23500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-25500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-27500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-28500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-29500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-33500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-36500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-38500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-42500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-43500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-44500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-46500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-47500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-48500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-49500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-50500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-51500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-52500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-53500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-54500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-55500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-56500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-57500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-58500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-59500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62000\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62000/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-60500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62500\n",
      "Configuration saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62500/config.json\n",
      "Model weights saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-62500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-p-l-akk-en-20220725-224830/checkpoint-61000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1728\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=62850, training_loss=1.4417311488282805, metrics={'train_runtime': 8234.1664, 'train_samples_per_second': 61.041, 'train_steps_per_second': 7.633, 'total_flos': 1.0294543513534464e+17, 'train_loss': 1.4417311488282805, 'epoch': 30.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TranslationPipeline(model=model.to(\"cpu\"), tokenizer=tokenizer, max_length=model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text2text_generation.TranslationPipeline at 0x7fc612096e30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Bonjour, mon nom est Frank.'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"translate English to French: hello my name is Frank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate Akkadian to English: a-na ti-lu-ti-szu-nu\n",
      "--------------------------------------------------------------------------------\n",
      "and to their assistance\n"
     ]
    }
   ],
   "source": [
    "source_test = translations[\"test\"][0][\"source\"]\n",
    "target_test = translations[\"test\"][0][\"target\"]\n",
    "print(source_test)\n",
    "print(\"-\"*80)\n",
    "print(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'for their cultic duties'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(text):\n",
    "    return pipeline(text)\n",
    "\n",
    "translate(source_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na ti-lu-ti-szu-nu\n",
      "TARGET and to their assistance\n",
      "PRED   for their cultic duties\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: dumu ha-ri-ia#\n",
      "TARGET son of Hariya,\n",
      "PRED   son of Hariya,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na\n",
      "TARGET For\n",
      "PRED   to\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _musz igi-min_\n",
      "TARGET two-faced serpent.\n",
      "PRED   the eyewitness\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-na _e2-gal_-li-ia\n",
      "TARGET \"In my palace\"\n",
      "PRED   in my palace\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ma-gi-ir te-es3-li-ti-im\n",
      "TARGET who is agreeable to petition,\n",
      "PRED   a penalty of destitution\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _lugal_ ba-bi-i-lu{ki}\n",
      "TARGET king of Babylon,\n",
      "PRED   king of Babylon,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: me-ra-na-am u3 'a4-az-za-am isz-szu-ni-im-ma\n",
      "TARGET a puppy and a goat they brought!\n",
      "PRED   a tin and a ... he received, and\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-na _kur kaskal_-ni u3 szi-di _i7_ ha-bur\n",
      "TARGET in the land Harran and the region of the river Habur\n",
      "PRED   from the land Kashanu and the banks of the River Hadû\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na ba-la-t,i-szu\n",
      "TARGET for his life\n",
      "PRED   for his life\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {disz}{d}suen-e-ri-ba-am _dumu_ {d}suen-sze-mi#\n",
      "TARGET Sîn-eribam, son of Sîn-shēmi;\n",
      "PRED   Sîn-eribam, son of Sîn-szemi;\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _kur_ ha-at-te i-na _{gesz}ban_-ia dan-na-te\n",
      "TARGET the land Hattu with my strong bow,\n",
      "PRED   the land Hatti, with my mighty ban-naptials,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _gurusz-gurusz_-su\n",
      "TARGET his young men\n",
      "PRED   his men\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {disz}im-me-er-dingir _dumu e2-gal_ u3 za-ku-re-e-lum _sza3 guru7_ iri{ki}-ARAD2-{d}suen _sze i3-ag2-e_ _iti du6-ku3 u4 1(u) 4(disz)-kam _mu inim {d}suen {d}en-lil2 {d}en-ki-ga-ta i7 buranun-na-be2 di4-lim-da ku3-ga {d}nanna-ke4 sipa zi {d}ri-im-{d}suen mu-un-ba-al-la2_\n",
      "TARGET Immer-ili, son of the palace, and Zakur-elum, in the silo of Al-warad-Sin, the barley they shall measure out; month: “Silver hill,” 14th day, year: “By the order of Sin, Enlil, and Enki, a canal towards the Euphrates, the silvery cup of Nanna, Rim-Sin, the good shepherd, dug.”\n",
      "PRED   Immer-ilum, son of the palace, and Zakrlum, from the canal of the city Warad-Sîn the barley is rented. The month of Duku, the day 14 the year (in which) the name of Sîn, Enlil, Enkigata (and) the Euphrates the dilimda of gold (giving) to Nanna the scepter of Rim-Sîn he presented.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na ki-is,-ri\n",
      "TARGET against payment of rent,\n",
      "PRED   to cultivate\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-na qit-ru-ub mi-it,-lu-ti-ia i-na _giri3-mesz_-ia lu a-duk u3 8(disz) me _ur-mah-mesz__ i-na _{gesz}gigir_-ia i-na pat-tu-te u2-szem-qit2 bu-ul {d}szakkan2 gi-mir-ta u3 _muszen an_-e mut-tap-ri-sza e-em ni-sik _gi-mesz_-ia lu-u2 at-ta-ad-di isz-tu _kur-mesz_-ut {d}a-szur pat, gim-ri-szu-nu a-pe-lu _e2_ {d}inanna asz2-szu-ri-te _nin_-ia _e2_ {d}mar-tu _e2_ {d}en-libir-ra _e2_ {d}1(u)-te _e2-hi-a-mesz dingir-mesz_-ni an-hu-te sza2 _iri_-ia {d}a-szur e-pu-usz u2-szek2-lil te-ru-bat _e2-hi-a-mesz_-szu-nu asz2-kun _dingir-mesz gal-mesz en-mesz_-ia a-na lib3-bi u2-sze-rib\n",
      "TARGET in combat heroic, on foot I verily killed; and 800 lions in my chariot in the open I felled; all of the creatures of Shakkan and birds of the sky flying with the bite of my reeds I brought low.        \n",
      "PRED   I killed my limbs with my chariotry and 8 hundred were my lions with my chariotry. I killed the great gods, my lord, and the ostriches in my presence I killed. I fought with the lions and the ostriches, my companions. From the lands that Assur conquered, the house of Ishtar, their chief shepherd, the house of Martu, the house of Enlibirra, the house of Ishtar, the houses of the gods, my city, Assur built and destroyed their foundations. I surrounded them with a wall and surrounded them with the gods, my lords, my lords, my lords,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-ta2-ah-za-ma\n",
      "TARGET grappled with each other.\n",
      "PRED   has seized and\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: id-di-nu-szum\n",
      "TARGET he gave to him,\n",
      "PRED   gave to him,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ki-ib-ra-at ar-ba-im\n",
      "TARGET the four quarters\n",
      "PRED   the four world quarters\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na be-li-im\n",
      "TARGET to rule\n",
      "PRED   to rule\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u3 u3-sza-asz2-t,a2-ru\n",
      "TARGET or shall cause it to be written,\n",
      "PRED   and he shall remove,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u-su-s,i2\n",
      "TARGET he made go forth,\n",
      "PRED   he caused to dwell,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u3 a-szu-um er-re-tim\n",
      "TARGET or because of the curse\n",
      "PRED   and that one cursed.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u2-ra-ap-pi2-isz\n",
      "TARGET he widened\n",
      "PRED   he made stand.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u3 il3-a-ba4\n",
      "TARGET and Ilaba,\n",
      "PRED   and Ilaba\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {disz}szu-ub-na-lu-u2\n",
      "TARGET Shubna-Lu\n",
      "PRED   Shubnalû,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ba-ri2-ti\n",
      "TARGET in between\n",
      "PRED   my mother\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: mi-im-ma# t,e4-mu-um i-na li-ib-bi-szi-na\n",
      "TARGET (then it is as if) a report in them\n",
      "PRED   whatever information in their hearts\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _sze-numun_-su li-il-qu3-ta2\n",
      "TARGET (The gods ...) his seed may they tear out.\n",
      "PRED   his seed pluck up.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {disz}lu2-dingir-ra x [...]\n",
      "TARGET Lu-dingira\n",
      "PRED   Lu-ilu ...,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: na-ra-am il3-a-ba4\n",
      "TARGET beloved of Ilaba\n",
      "PRED   beloved of Ilaba,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: li-ik-ru-bu\n",
      "TARGET they must dedicate.\n",
      "PRED   may they write you.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: e-pir6-mu-pi5 _szagina_ ma-ti elam{ki}\n",
      "TARGET Epir-mupi, military governor of the land of Elam.\n",
      "PRED   Epir-mupi, general of the land of Elam.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: be-li2-e-mu-qi2\n",
      "TARGET Bēli-emuqi,\n",
      "PRED   Bli-muqi,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _u4# 4(disz)-kam2_\n",
      "TARGET 4th day,\n",
      "PRED   the 4th day,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _dumu-mesz_ szi-ip-ri\n",
      "TARGET of the messengers\n",
      "PRED   the craftsmen\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: mu-[...]\n",
      "TARGET Mu...,\n",
      "PRED   Mu-...,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: at,#-t,a3-ar-dam\n",
      "TARGET I have dispatched.”\n",
      "PRED   I have sent.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: na-pi2-isz-ta-szu li-ki-is\n",
      "TARGET cut his throat.\n",
      "PRED   his life save!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: dal-ba-at{ki}\n",
      "TARGET of Dilbat,\n",
      "PRED   of Dalbat,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u3 u3-sza-ap-szu-t,u2\n",
      "TARGET or shall cause it to be effaced\n",
      "PRED   and he shall remove,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ka-an-ku il-qu2-nim!-ma\n",
      "TARGET sealed, they took and\n",
      "PRED   the potholder took away, and\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: [a]-na-ku u2-sza-aq-t,i3-il\n",
      "TARGET I had slaughtered;\n",
      "PRED   I have sent. They shall remove\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-din-{d}utu _sanga_ {d}nin-in-si-na _dumu_ ku3-{d}nin-in-si-na _ARAD_ a-bi-e-szu-uh-ke4\n",
      "TARGET Iddin-Shamash, sanga priest of the goddess Ninisina, son of Ku-Ninisina, servant of Abi-eshuh.\n",
      "PRED   Iddin-Shamash, sanga priest of Nininsina, son of Ku-Nininsina, servant of Abi-eshuh.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _ensi2_ ka-zal-lu{ki}\n",
      "TARGET governor of Kazallu;\n",
      "PRED   governor of Kazallu,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: pa2-ra-[ah-sum{ki}]\n",
      "TARGET Parahshum.\n",
      "PRED   Parahshum.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: it-ba-al\n",
      "TARGET \"he took away.\"\n",
      "PRED   he carried away,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: sza _dumu_ mi-im ik-mi\n",
      "TARGET of Mar Mîm he defeated.\n",
      "PRED   that a son something he did not know,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u2-sza-sa3-ku\n",
      "TARGET removes\n",
      "PRED   shall remove,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: x-x?-{d}x-x? _dumu_ ha-li-qum _ARAD2_ ha-am-mu-ra-pi2\n",
      "TARGET  son of Haliqum, servant of Hammurapi.\n",
      "PRED   ..., son of Haliqum, servant of Hammurapi.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: be-li2-szu\n",
      "TARGET his lord\n",
      "PRED   his lord,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: um-ma szu#-[u2-ma]\n",
      "TARGET he himself:\n",
      "PRED   thus that one:\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u3 [...] at-[...] mi-im#-[ma li-ib-ba-ka la i-na-hi-id]\n",
      "TARGET further, ... I ..., you need not be at all anxious.\n",
      "PRED   and ... whatever your heart desires, he will not reject.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {d}szar-ka3-li2-szar3-ri2 _lugal_ bu3-u-la-ti {d}en-lil2 tu-ta2-szar-li-bi2-isz2\n",
      "TARGET Shar-kali-sharri, king of the subjects of the god Enlil. Tuta-shar-libbish,\n",
      "PRED   Shar-kali-sharri, king of the habitations, Enlil, Tuta-shar-libish,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-na ma-ha-ar {d}utu a-na da-ri-a-tim\n",
      "TARGET before Shamash forever.\n",
      "PRED   before Shamash for eternity\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {d}i-szar-ki-di-su\n",
      "TARGET To Ishar-kîdissu,\n",
      "PRED   Ishar-kidishu,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _dumu_ a-x x x x\n",
      "TARGET son of A...,\n",
      "PRED   son of ...,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-szar-li-im _lugal kur_ ha-na _dumu_ i-din-{d}ka-ak-ka na-ra-am il3-a-ba4 u3 {d}da-gan\n",
      "TARGET Ishar-Lim, king of the land of Hana, son of Iddin-Kakka, beloved of Ilaba and Dagan.\n",
      "PRED   Ishar-Lim, king of the land of Hana, son of Iddin-Kakka, beloved of Ilaba and Dagan.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: um-ma i-ba-al-dingir\n",
      "TARGET Thus Ibal-El\n",
      "PRED   Thus Ibal-El,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {disz}a-ur2-na-hu-usz\n",
      "TARGET A'urnahush\n",
      "PRED   Urnahush,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {[d]}en-lil2\n",
      "TARGET Enlil,\n",
      "PRED   Enlil\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na qa3-ti-szu\n",
      "TARGET into his hands\n",
      "PRED   into his hands\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: tu-ta2-szar-li-bi2-isz2\n",
      "TARGET Tuta-shar-libbish,\n",
      "PRED   Tuta-shar-libish,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _lugal-mesz_ an-nu-tu-un\n",
      "TARGET these kings\n",
      "PRED   these kings\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {d}na3-ku#-du-ur2-ri-uri3\n",
      "TARGET Nebuchadnezzar,\n",
      "PRED   Nebuchadnezzar,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: um#-ma me-ep-tu-um _ARAD2_-ka-a-ma\n",
      "TARGET Thus Meptum, your servant:\n",
      "PRED   Thus Meptum, your servant:\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u3 _kur_ pu-ru-lum-zi na-a-asz2 _gun_\n",
      "TARGET and the land of Purulumzi, bearers of tribute\n",
      "PRED   and the Purumzi pass, the source of the oil\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-s,e2-er eq-lam\n",
      "TARGET \"in addition to taking a field\"\n",
      "PRED   an incantation against the land\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _ARAD_ il3-a-ba4\n",
      "TARGET servant of Ilaba,\n",
      "PRED   servant of Ilaba.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {d}nin-x\n",
      "TARGET May the gods Nin-x\n",
      "PRED   Nin-...,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-re-ed-du ta-ki-il\n",
      "TARGET will they lead? He is trustworthy\n",
      "PRED   they shall lead you, you shall swear;\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _dumu_ szesz-kal-la _ARAD-zu_\n",
      "TARGET son of Shesh-kalla, your servant.\n",
      "PRED   son of Shshkalla, your servant.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: re-szi-szu\n",
      "TARGET its top\n",
      "PRED   his top\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {d}a-a ka-la-tum\n",
      "TARGET May the daughter-in-law Aia,\n",
      "PRED   Ayya, the mighty,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ka3-ma-ar-szu-nu#\n",
      "TARGET (and) their defeat\n",
      "PRED   their witnesses\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: me-eh-ha-am qa-at-nam ta-ra-as-sa3-an\n",
      "TARGET You will soak the delicate part (of the cloth) in beer,\n",
      "PRED   a short one, short one, you will be seized.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: is2-kun3\n",
      "TARGET he consigned them.\n",
      "PRED   he smote,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: [{d}utu]\n",
      "TARGET Shamash,\n",
      "PRED   Shamash\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: be-el-tum ra-bi-tum lu mu-le-mi-na-at a-wa-ti-szu i-na ma-ha-ar {d}utu a-na da-ri-a-tim {d}bu-ne2-ne2 szu-ka-al {d}utu ra-bu-um na-pi2-isz-ta-szu li-ki-is ze-ra-szu li-il-qu2-ut-ma pi2-ri-ih-szu u3 szum-zu i-na ma-ha-ar {d}utu a-ii-ta-la-ak\n",
      "TARGET the great lady, speak badly of him before Shamash forever. May Bunene the cheif vizier of Shamash cut his throat. May he pluck up his seed, and may his offspring and progeny : not walk in the presence of Shamash.\n",
      "PRED   May the great lord be able to fulfill his pronouncements before Shamash forever, may Bunene be his ear forever. May Shamash, the great lord, his life preserve, and his foundations pluck up, and his fruit and his reputation before Shamash may he not walk.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: na-ap-ta-nu-um la i-ba-a et-ru-ba-am-ma\n",
      "TARGET The meal time should not pass—go in there, and\n",
      "PRED   the stele he did not know entered, and\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: li-il-qu2-nim-ma t,up-pa-tum szi-na\n",
      "TARGET let them take, and those tablets\n",
      "PRED   pluck up, and that tablet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _ARAD2_ ha-ia-a-bu-um\n",
      "TARGET servant of Haya-abum,\n",
      "PRED   servant of Haia-abum.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {d}a-ia-lum _lugal_ a-ba-at-tim{ki}\n",
      "TARGET Aialum, king of Abattum\n",
      "PRED   Ilum, king of the land of\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _e2-gal_ {disz}asz-pap-a _man szu2_ _man kur_ asz _a_ geszkim-masz _man kur_ asz-ma\n",
      "TARGET (Property of) the palace of Assurnasirpal, king of everything, king of Assyria, son of Tukulti-Ninurta, king of Assyria.\n",
      "PRED   Palace of Assurnasirpal, king of the universe, king of Assyria, son of Geshkimash, king of Assyria.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: lugal:dingir-kalam\n",
      "TARGET of the god Bēl-matim,\n",
      "PRED   Shar-ilam,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: in ki-ib-ra-tim\n",
      "TARGET throughout the world quarters\n",
      "PRED   in the world quarters\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: kisz{ki}-szi-am\n",
      "TARGET over the Kishite\n",
      "PRED   of Kish,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-na mit-hu-us, tu-sza-ri ki-ma ra-hi-s,e\n",
      "TARGET in the destructive plain like a flood\n",
      "PRED   with a slap like a lion\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: li-su2-ha\n",
      "TARGET rip out\n",
      "PRED   tear out\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: mu-gam-me-ru bu-'u-ur s,e-ri\n",
      "TARGET expert of the hunt of the steppe:\n",
      "PRED   who makes obedient the mind,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _nu-banda3_-u3 kisz{ki} u3\n",
      "TARGET captains of Kish; and\n",
      "PRED   the mayors of Kish and\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: [x] li GA mi _gu2-un_\n",
      "TARGET ... load/talent\n",
      "PRED   ... he did not have a neck\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: na-asz2-pe3-er-tum sza i-ku-pi3-a\n",
      "TARGET order of Ikuppiya\n",
      "PRED   “Order” of Ikupiya.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-pi2-iq-{d}iszkur na-ra-am {d}tiszpak _ensi2_ asz2-nun-na{ki}\n",
      "TARGET Ipiq-Adad, beloved of Tishpak, governor of Eshnunna.\n",
      "PRED   Ipiq-Adad, beloved of Tishpak, governor of Eshnunna.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: [i-na li-ib-bi t,up-pa]-tim# sza-t,e4-er\n",
      "TARGET in the tablets is recorded;\n",
      "PRED   In the heart of a tablet is written,\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ti-la-ab-nu-u2\n",
      "TARGET Tilabnû,\n",
      "PRED   they shall levy;\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u _{lu2}szid_ {disz}szum2-nu-nu _a_\n",
      "TARGET and the scribe Iddinunu, descendant of\n",
      "PRED   and the scribe Shumnunu, son\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ni-ik-ka-sa3-am\n",
      "TARGET the account\n",
      "PRED   a contract\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _e2-gal_ lu2-{d}marduk _lugal_ babilax(|TIN.TIR|){ki}\n",
      "TARGET Palace of Amēl-Marduk, king of Babylon,\n",
      "PRED   Palace of Aml-Marduk, king of Babylon.\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: [u3] e2#-zi#-[da]\n",
      "TARGET and the E-zida,\n",
      "PRED   and the E-zida,\n"
     ]
    }
   ],
   "source": [
    "tests = original_tests\n",
    "def sample(num_samples=100):\n",
    "    for i in range(min(num_samples, tests.num_rows)):\n",
    "        t = tests[i]\n",
    "    #     print(t)\n",
    "        src = t[\"source\"]\n",
    "        tgt = t[\"target\"]\n",
    "        query = src\n",
    "        pred = pipeline(query)[0][\"translation_text\"]\n",
    "        print(\"-\"*48)\n",
    "        print(\"QUERY \", query)\n",
    "        print(\"TARGET\", tgt)\n",
    "        print(\"PRED  \", pred)\n",
    "    #     break\n",
    "    \n",
    "sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained\n",
      "Configuration saved in /home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/config.json\n",
      "Model weights saved in /home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/pytorch_model.bin\n",
      "tokenizer config file saved in /home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/tokenizer_config.json\n",
      "Special tokens file saved in /home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.abspath(f\"/home/fak/nn/Data/generated/cuneiform/{model_id}-fullytrained\")\n",
    "trainer.save_model(model_path)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/tokenizer_config.json\n",
      "Special tokens file saved in /home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/tokenizer_config.json',\n",
       " '/home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/special_tokens_map.json',\n",
       " '/home/fak/nn/Data/generated/cuneiform/t5-base-p-l-akk-en-20220725-224830-fullytrained/tokenizer.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
