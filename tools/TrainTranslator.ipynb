{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune\n",
    "\n",
    "Based on: https://huggingface.co/docs/transformers/tasks/translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, datetime\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import TranslationPipeline\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Finetune.ipynb\"\n",
    "\n",
    "source_langs = set([\"akk\", \"sux\"])\n",
    "\n",
    "target_langs = set([\"en\", \"it\", \"es\", \"fr\", \"de\"])\n",
    "\n",
    "base_model_id = \"t5-base\"\n",
    "\n",
    "model_max_length = 256\n",
    "batch_size = 32\n",
    "num_train_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t5-base-bi-akk-sux-20220719-133120'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_id = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_id = f\"{base_model_id}-bi-{'-'.join(sorted(list(source_langs)))}-{date_id}\"\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, <torch.cuda.device at 0x7f7b4938ab30>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_cuda = torch.cuda.is_available()\n",
    "device = torch.cuda.device(0) if has_cuda else \"cpu\"\n",
    "has_cuda, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 19 13:31:21 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 30%   46C    P8    34W / 350W |    168MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A       971      G   /usr/lib/xorg/Xorg                120MiB |\r\n",
      "|    0   N/A  N/A      1236      G   ...ome-remote-desktop-daemon        4MiB |\r\n",
      "|    0   N/A  N/A      1272      G   /usr/bin/gnome-shell               23MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_full = {\n",
    "    \"akk\": \"Akkadian\",\n",
    "    \"sux\": \"Sumerian\",\n",
    "    \"akkts\": \"Akkadian\",\n",
    "    \"suxts\": \"Sumerian\",\n",
    "    \"en\": \"English\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"de\": \"German\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate Sumerian to Spanish: '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prefix(src_lang, tgt_lang):\n",
    "    s = lang_full[src_lang]\n",
    "    t = lang_full[tgt_lang]\n",
    "    return f\"translate {s} to {t}: \"\n",
    "    \n",
    "get_prefix(\"suxts\", \"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-dc8b07d8fd701d7f\n",
      "Reusing dataset json (/home/fak/.cache/huggingface/datasets/json/default-dc8b07d8fd701d7f/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f611eda3d942888c92b166b4331300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['p', 'a', 'l', 'sux', 'en', 'akk', 'akkts', 'de', 'suxts', 'fr', 'elx', 'es', 'it'],\n",
       "        num_rows: 74584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations = load_dataset(\"json\", data_files=\"../data/translations.jsonl\")\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = [\n",
    "    (\"ā\", \"a\"),\n",
    "    (\"Ā\", \"a\"),\n",
    "    (\"ḫ\", \"h\"),\n",
    "    (\"Ḫ\", \"H\"),\n",
    "    (\"ī\", \"i\"),\n",
    "    (\"Ī\", \"I\"),\n",
    "#     (\"î\", \"i\"),\n",
    "#     (\"Î\", \"I\"),\n",
    "    (\"ř\", \"r\"),\n",
    "    (\"Ř\", \"R\"),\n",
    "    (\"š\", \"sh\"),\n",
    "    (\"Š\", \"Sh\"),\n",
    "    (\"ṣ\", \"sh\"),\n",
    "    (\"Ṣ\", \"Sh\"),\n",
    "    (\"ū\", \"u\"),\n",
    "    (\"Ū\", \"U\"),\n",
    "]\n",
    "def replace_unsupported(text):\n",
    "    r = text\n",
    "    for s, t in replacements:\n",
    "        r = r.replace(s, t)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing akk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39792919af4a40299d7cfa9067bec269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing sux\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb477a10ee3428fa1bd9fd32308dc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 140868\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourceandtargets = []\n",
    "for s in source_langs:\n",
    "    print(\"Preparing\", s)\n",
    "    for t in tqdm(target_langs):\n",
    "        st_prefix = get_prefix(s, t)\n",
    "        ts_prefix = get_prefix(t, s)\n",
    "        for line in translations[\"train\"]:\n",
    "            ls = line[s]\n",
    "            lt = line[t]\n",
    "            if ls is not None and lt is not None:\n",
    "                lt = replace_unsupported(lt)\n",
    "                if lt[-1] == \".\" or lt[-1] == \"!\" or lt[-1] == \";\" or lt[-1] == \",\":\n",
    "                    lt = lt[:-1]\n",
    "                sourceandtargets.append((st_prefix + ls, lt))\n",
    "                sourceandtargets.append((ts_prefix + lt, ls))\n",
    "                \n",
    "random.shuffle(sourceandtargets)\n",
    "translations = Dataset.from_dict({\"source\": [x[0] for x in sourceandtargets], \"target\": [x[1] for x in sourceandtargets]})\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 126781\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 14087\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations = translations.train_test_split(test_size=0.1)\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 14087\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = translations[\"test\"]\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, model_max_length=model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad <pad> 0\n",
      "eos </s> 1\n",
      "unk <unk> 2\n"
     ]
    }
   ],
   "source": [
    "print(\"pad\", tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(\"eos\", tokenizer.eos_token, tokenizer.eos_token_id)\n",
    "print(\"unk\", tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_function at 0x7f7b48291870> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7301cc6e59f5427484b5e65d42124293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13959, 1566, 12, 4823, 1258, 8603, 10, 9927, 6, 11, 1]\n",
      "[3, 23, 18, 526, 18, 15, 7, 172, 18, 51, 9, 1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c701010e295448359f4f6acdeb3dfac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 126781\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14087\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc = 0\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    global ccc\n",
    "#     print(examples)\n",
    "    inputs = [example for example in examples[\"source\"]]\n",
    "    targets = [example for example in examples[\"target\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=model_max_length, truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=model_max_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    ccc += 1\n",
    "    if ccc == 1:\n",
    "        print(model_inputs[\"input_ids\"][0])\n",
    "        print(model_inputs[\"labels\"][0])\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_translations = translations.map(preprocess_function, batched=True)\n",
    "tokenized_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 14087\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_translations[\"train\"].remove_columns([\"source\", \"target\"])\n",
    "tokenized_translations[\"test\"].remove_columns([\"source\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 194)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_max_length = max([len(x[\"input_ids\"]) for x in tokenized_translations[\"train\"]])\n",
    "target_max_length = max([len(x[\"labels\"]) for x in tokenized_translations[\"train\"]])\n",
    "source_max_length, target_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 23, 18, 526, 18, 15, 7, 172, 18, 51]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_translations[\"train\"][0][\"labels\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-base\",\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 3072,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.19.4\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForSeq2Seq(tokenizer=PreTrainedTokenizerFast(name_or_path='t5-base', vocab_size=32100, model_max_len=256, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}), model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       "), padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"../results/{model_id}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2*2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    fp16=has_cuda,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_translations[\"train\"],\n",
    "    eval_dataset=tokenized_translations[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/fak/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 126781\n",
      "  Num Epochs = 400\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1584800\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpraeclarum\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/fak/Projects/CuneiformTranslators/tools/wandb/run-20220719_133250-28b4hbbw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/praeclarum/huggingface/runs/28b4hbbw\" target=\"_blank\">../results/t5-base-bi-akk-sux-20220719-133120</a></strong> to <a href=\"https://wandb.ai/praeclarum/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119047' max='1584800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 119047/1584800 4:30:45 < 55:33:45, 7.33 it/s, Epoch 30.05/400]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.942400</td>\n",
       "      <td>1.670588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.615400</td>\n",
       "      <td>1.432208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.461800</td>\n",
       "      <td>1.294569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.328800</td>\n",
       "      <td>1.210426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.255400</td>\n",
       "      <td>1.147311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.175200</td>\n",
       "      <td>1.099326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.120100</td>\n",
       "      <td>1.058509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.074600</td>\n",
       "      <td>1.030408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.019100</td>\n",
       "      <td>1.007711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.963500</td>\n",
       "      <td>0.981915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.971100</td>\n",
       "      <td>0.965160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.883800</td>\n",
       "      <td>0.937195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.855600</td>\n",
       "      <td>0.925409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.830700</td>\n",
       "      <td>0.913142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.806300</td>\n",
       "      <td>0.906555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.776500</td>\n",
       "      <td>0.894791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.758100</td>\n",
       "      <td>0.892474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>0.884418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.884347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.701700</td>\n",
       "      <td>0.879287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.879039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.665600</td>\n",
       "      <td>0.871889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.658900</td>\n",
       "      <td>0.872370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.870248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>0.866662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.612700</td>\n",
       "      <td>0.870186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.595400</td>\n",
       "      <td>0.869445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.572700</td>\n",
       "      <td>0.856480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.590600</td>\n",
       "      <td>0.824281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-13500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-17500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-18500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-21500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-23500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-25500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-27500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-28500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-29500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-33500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-36500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-38500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-42500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-43500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-44500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-46500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-47500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-48500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-49500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-50500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-51500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-52500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-53500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-54500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-55500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-56500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-57500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-58500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-59500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-60500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-61500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-62500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-63500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-64500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-65500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-66500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-67500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-68500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-69500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-70500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-71500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-72500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-73500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-74500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-75500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-76500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-77500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-78500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-79500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-80500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-81500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-82500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-83500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-84500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-85500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-86500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-87500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-88500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-89500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-90500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-91500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-92500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-93500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-94500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-95500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-96500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-97500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-98500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-99500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-100500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-101500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-102500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-103500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-104500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-105500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-106500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-107500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-108500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-109500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-110500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-111500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-112500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-113500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-114500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-115500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-116500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118500\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118500/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-118500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14087\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-119000\n",
      "Configuration saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-119000/config.json\n",
      "Model weights saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-119000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-119000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-119000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-bi-akk-sux-20220719-133120/checkpoint-117500] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1317\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1314\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1316\u001b[0m )\n\u001b[0;32m-> 1317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1614\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_grad_scaling:\n\u001b[1;32m   1613\u001b[0m     scale_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mget_scale()\n\u001b[0;32m-> 1614\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m   1616\u001b[0m     scale_after \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mget_scale()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 338\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:285\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 285\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/optimization.py:380\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;66;03m# Just adding the square of the weights to the loss function is *not*\u001b[39;00m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;66;03m# the correct way of using L2 regularization/weight decay with Adam,\u001b[39;00m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;66;03m# since that will interact with the m and v parameters in strange ways.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[38;5;66;03m# of the weights to the loss with plain (non-momentum) SGD.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;66;03m# Add weight decay at the end (fixed version)\u001b[39;00m\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m--> 380\u001b[0m             \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TranslationPipeline(model=model.to(\"cpu\"), tokenizer=tokenizer, max_length=model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text2text_generation.TranslationPipeline at 0x7f7a7d584100>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'me-te ma mme nidba'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"translate English to French: hello my name is Frank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate Sumerian to English: a2 gesz-ur3-ra\n",
      "--------------------------------------------------------------------------------\n",
      "work of harrowing\n"
     ]
    }
   ],
   "source": [
    "source_test = translations[\"test\"][0][\"source\"]\n",
    "target_test = translations[\"test\"][0][\"target\"]\n",
    "print(source_test)\n",
    "print(\"-\"*80)\n",
    "print(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'labor of harrowing'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(text):\n",
    "    return pipeline(text)\n",
    "\n",
    "translate(\"translate Sumerian to English: a2 gesz-ur3-ra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: a2 gesz-ur3-ra\n",
      "TARGET work of harrowing\n",
      "PRED   labor of harrowing\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: and\n",
      "TARGET [u3]\n",
      "PRED   u3\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: dumu-[(x)]\n",
      "TARGET (...) son\n",
      "PRED   the son(?)\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: abul# nig2-ku5-da\n",
      "TARGET Gate of the Nigku taxes\n",
      "PRED   in the city gate taken\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: lagasz\n",
      "TARGET of Lagash\n",
      "PRED   of Lagash\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: n sheep, barley-fed, of Lugal-magure\n",
      "TARGET [n] udu niga lugal-ma2!-gur8-re\n",
      "PRED   [n] udu niga lugal-ma2-gur8#-re#\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: e2-mar-uru5-sze3\n",
      "TARGET and into a quiver\n",
      "PRED   to the E-maru\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: iti ezem-me-ki-gal2?\n",
      "TARGET month: “Festival-of-Mekigal(?),”\n",
      "PRED   month: “Festival of Mekigal,”\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: king of the four corners:\n",
      "TARGET lugal an ub-da limmu2-ba\n",
      "PRED   lugal an ub-da limmu2-ba\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: of Awal\n",
      "TARGET a-ba-al{ki}\n",
      "PRED   a-wa-alki\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: and for its land\n",
      "TARGET a-na er-s,e-[ti-szu]\n",
      "PRED   a-na ma-ti-szu\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: to Nergal-Lamassashu\n",
      "TARGET [a]-na# {d}ne3-iri11-gal-la-ma#-sa3-szu#\n",
      "PRED   a-na diszdu-gur-dmasz-szum2\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: a iri gul-la e2 gul-la-gu10 gig-ga-bi im-me\n",
      "TARGET “Alas, the destroyed city, my destroyed house.”\n",
      "PRED   “Alas, the destroyed city, my destroyed house.”\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _ARAD_ s,il2-li2-{d}suen\n",
      "TARGET servant of Shilli-Sîn\n",
      "PRED   servant of Shilli-Sîn\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _dingir_ gu-ti-im\n",
      "TARGET the god of Gutium\n",
      "PRED   the god of Gutium\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 3(asz) en#?-ra-kal\n",
      "TARGET 3: Enrakal\n",
      "PRED   3 (gur) Enracal\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: from Lu-Zabala\n",
      "TARGET ki lu2-zabala3{ki}-ta\n",
      "PRED   ki lu2-zabala3ki-ta\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: geszkim-ti {d}utu {d}iszkur-bi-da-ke4\n",
      "TARGET by the aid of Utu and Ishkur\n",
      "PRED   the trusted one of Utu and Ishkur\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: to the school-fathers friendly words speaks:\n",
      "TARGET ad-da e2-dub-ba-a-ke4-ne gu2-hul2 ba-ni-de2-e\n",
      "PRED   a-a e2-dub-ba-ke4 inim sa6-sa6-ge gu3 mu-na-de2-e\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: i3-gal2\n",
      "TARGET are here\n",
      "PRED   are here\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: [...]-she\n",
      "TARGET [...]-x-sze3{ki}\n",
      "PRED   [...]-sze3ki\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: 36 female laborers, (each of whom received) 3 ban (per month)\n",
      "TARGET 3(u) 6(disz) geme2 3(ban2)\n",
      "PRED   3(u) 6(disz) geme2 3(ban2)\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: in his exalted temple, for offerings\n",
      "TARGET e2 mah siskur2-ra\n",
      "PRED   e2 mah-a-ni gesz-tag-ga\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: um#-ma#-um-ma-ar i3-na-ab#[{ki}-a]\n",
      "TARGET The old women of Inab\n",
      "PRED   Umma-um-mara of Inab\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: i7 x [...]\n",
      "TARGET the river ..\n",
      "PRED   the ... canal\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: the roasted part\n",
      "TARGET sza-ba-im e-ku-lu-ni\n",
      "PRED   sza szu-ri-bu-u2\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: ..., I -\n",
      "TARGET [...] x a-na-ku\n",
      "PRED   [...]-x-ma a-na-ku\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: ..\n",
      "TARGET [...] sa [...] x IGI [...] du8\n",
      "PRED   [...]\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: from Hahhum ..\n",
      "TARGET isz-tu3 ha-hi-im a#?-[...]\n",
      "PRED   i-na ha-hi-imki [...]\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: hur-sag-ga2 bar im-ma-an-dab5-be2-esz edin-lil2-e ba-ab-[...]\n",
      "TARGET They hid out in the hills and wandered (?) about in the haunted plains\n",
      "PRED   The mountains were swept away by storm, ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [...]-in-il2\n",
      "TARGET ... he raised ..\n",
      "PRED   ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: szud3-de3 an\n",
      "TARGET It is a prayer of An\n",
      "PRED   to raise the brow\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: against the king did hostilites\n",
      "TARGET lugal-da gu2 erim2\n",
      "PRED   lugal-e ki bala-a\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: and had him swear by it\n",
      "TARGET nam e-na-ta-ku5\n",
      "PRED   nam e-na-ta-esz-a\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: Enmetena\n",
      "TARGET en-mete-na\n",
      "PRED   en-mete-na\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _sa12-rig9_\n",
      "TARGET he presented it (this statue)\n",
      "PRED   he presented\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: ..\n",
      "TARGET [...]\n",
      "PRED   [...]\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: king of the four corners:\n",
      "TARGET lugal an ub-da limmu2-ba\n",
      "PRED   lugal an ub-da limmu2-ba\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to German: mu ur-{d}nin-gesz-zi-da simug\n",
      "TARGET — wegen Ur-Ningeshzida, des Schmieds\n",
      "PRED   Jahr: “Ur-Ningeshzida, der Schmiedtscher\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: 25 sar of hoeing at 5 sar (a day)\n",
      "TARGET 2(u) 5(disz) sar al 5(disz) sar-ta\n",
      "PRED   2(u) 5(disz) sar al 5(disz) sar-ta\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: mu-na-du3\n",
      "TARGET he built for her\n",
      "PRED   he built for him\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: URU-KA-gina\n",
      "TARGET URU-KA-gi-na\n",
      "PRED   URU-KA-gi-na\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: the maiden seized, and\n",
      "TARGET {munus}ba-tul-ta is,-ba-at-ma\n",
      "PRED   s,a-ba-am i-ra-ab-bi-ma\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: a-sza3 sipa-da\n",
      "TARGET field Herder\n",
      "PRED   field Shepherd-da\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u-kal2-la-mu-ma\n",
      "TARGET he shall incite, and\n",
      "PRED   I made known to me, and\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: dam-a-ne2\n",
      "TARGET her husband\n",
      "PRED   his wife\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: szunigin 6(gesz2) 2(u) erin2#?\n",
      "TARGET total: 380 labor-troops, in bala stationed\n",
      "PRED   total: 420 labor-troops(?)\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _numun#_-szu#\n",
      "TARGET his seed\n",
      "PRED   his seed\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: 1 mountain ram, slaughtered\n",
      "TARGET 1(disz) udu-nita2# kur-ra ba-usz2\n",
      "PRED   1(disz) udu kur ba-usz2\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: tukum-bi#\n",
      "TARGET If\n",
      "PRED   If\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: who was unmarried, ‘You had sexual relations,’\n",
      "TARGET e2 nu-un-gi4-a gesz3 i3-zu\n",
      "PRED   nu-tuku-me-en3 a-gin7 ba-tuku\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na _ka_ s,i-im-da-at\n",
      "TARGET in accordance with the edict\n",
      "PRED   to the mouth of the slanderer\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: ...\n",
      "TARGET kaskal-mah-x\n",
      "PRED   geszuzu x-x\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: 1 sheep\n",
      "TARGET 1(disz) udu\n",
      "PRED   1(disz) udu\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _lugal kisz_\n",
      "TARGET king of the world\n",
      "PRED   king of the world\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: iti u5-bi2-gu7\n",
      "TARGET month: “Ubi feast,”\n",
      "PRED   month: “ubi-feast,”\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: of Nabopolassar\n",
      "TARGET sza {d}na3#-[ibila-uri3]\n",
      "PRED   sza dna3-ibila-uri3\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 4(disz) gurusz ugula tab-sza-[la]\n",
      "TARGET 4 male laborers, foreman: Tabshala\n",
      "PRED   4 male laborers, foreman: Tabshal\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: e2-dam\n",
      "TARGET The Edam\n",
      "PRED   The Etam\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: tam2-si4-il-su\n",
      "TARGET an image of himself\n",
      "PRED   a bond with him\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: nu-banda3 lu2-{d}nin-gir2-su\n",
      "TARGET the overseer: Lu-Ningirsu\n",
      "PRED   the overseer: Lu-Ningirsu\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: e-la kab-ta-ti-szu2 a-a-u2 li-sza2-lil _szu-min_-su\n",
      "TARGET Without his weightiness, who would causes to hang his hands?\n",
      "PRED   “When I was going to the shelter, I was going to the shelter, my sleeping place\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _DISZ_ mi-iq-tum#? x x x\n",
      "TARGET ..\n",
      "PRED   ..\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: ..\n",
      "TARGET [...]-ni#-um\n",
      "PRED   [...]\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: Together: 51 gur 5 ban2 6 sila3 15 shekels barley\n",
      "TARGET szunigin 5(u) 1(asz) 5(ban2) 6(disz) sila3 1(u) 5(disz) gin2 sze gur\n",
      "PRED   szunigin 5(u) 1(asz) 5(ban2) 6(disz) sila3 1(u) 5(disz) gin2 sze gur\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: May wise Nin-imma'imma cool your heart with pleasant conversations\n",
      "TARGET {d}nin-imma3-imma3 gal-an-zu un-gi bar ze2-eb-be2-ba-ke4 ur5-zu he2-en-ib2-sze4-de3 = %a _{d}min_ er-szi ina na-pa-le-e t,u-ub ka-bat-ti ka-bat-ta-ka li-szap-szih\n",
      "PRED   dnin-imma-imma nig2-sikil-e sza3-zu du10-ga he2-nun-ne\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 3(disz) ba-a!(MIN)-a!(MIN)#\n",
      "TARGET 3 (mana wool for) Ba’aya\n",
      "PRED   3 (mana wool for) Ba’a’a\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: tu-ur2-ru\n",
      "TARGET was taken captive\n",
      "PRED   the new-year\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: kar-gul-la2-bi 1(asz) gu2-sze3 1(u) 1/2(disz) gin2-ta\n",
      "TARGET its market value for 1 talent: 10 1/2 shekels (of silver) each\n",
      "PRED   Their embankments: 1 talent 10 1/2 shekel each\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: lu2 di tuku\n",
      "TARGET a person having a lawsuit\n",
      "PRED   who has a claim\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: 1 bur3 5 iku surface area at 10 each\n",
      "TARGET 1(bur3) 5(iku) 1/2(iku) GAN2 1(u)-ta\n",
      "PRED   1(bur3) 5(iku) GAN2 1(u)-ta\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: beloved by him\n",
      "TARGET [ki]-ag2-ni\n",
      "PRED   ki-ag2-ni\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: Impression from a diorite brick(-stamp)\n",
      "TARGET zi-i-pa a-gur-ru _{na4}esi_\n",
      "PRED   szu-ta-at _esz-sza3-ga_\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: and their cowherds\n",
      "TARGET unu3-bi\n",
      "PRED   sipa-bi\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: in Ur\n",
      "TARGET sza3 uri5{ki}-ma\n",
      "PRED   sza3 uri5ki-ma\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: to a virgin grown\n",
      "TARGET [ki]-sikil# mu2-a\n",
      "PRED   ki-sikil-la2 mu2-a\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: ..\n",
      "TARGET [...] x x\n",
      "PRED   [...]\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: or destroys it\n",
      "TARGET ib2-ze-re-a\n",
      "PRED   u3 ib2-zi-re-a\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 1(asz) gu2 kas-tu7 lu2 mar-ha-szi{ki}\n",
      "TARGET 1 talent, ... for the man from Marhashi\n",
      "PRED   1 ashtu (gur), ... of Marhashi\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: son o f Sîn-iqisham\n",
      "TARGET dumu {d}suen-i-qi2-sza-am\n",
      "PRED   dumu dsuen-i-qi2-sza-am\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: sza3 uri5{ki}-ma\n",
      "TARGET in Ur\n",
      "PRED   in Ur\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ki-i-ki-i _pad_ la ba-na-a u3 _kasz-sag_ la t,a-ba\n",
      "TARGET How come that I have let food, which is not good, and first quality beer, which is not good tasting\n",
      "PRED   I did not rip off or pour beer or wine\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: dam sza3-ge pa3-da\n",
      "TARGET spouse chosen by the stomach\n",
      "PRED   the spouse chosen by the heart\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: giri3 ama-na-sze3 a-a-na-sze3 kur gam-gam-e in-na-an-ne-esz-am3\n",
      "TARGET they have told to make the foreign countries bow at the feet of his father and mother\n",
      "PRED   They were approached by the foot by her mother, the sea, for the sake of her children\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: bad3 mah hu-mu-du3\n",
      "TARGET and the great wall I built\n",
      "PRED   and the great wall I built\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: a-sza3 zalag-ga\n",
      "TARGET field Flash\n",
      "PRED   field Flash\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: sza2 _kur-ansze_-szu2 {disz}ir-hu-le-na _kur_ a-mat-a-a a-di _man-mesz_-ni\n",
      "TARGET the Damascene, Irhulēnu, the Hamatite, together with the kings\n",
      "PRED   of his land Irhuleser, the land of Apapa, together with kings\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: sag nam-ra-asz ak-ni-ta\n",
      "TARGET with the persons he had made into booty\n",
      "PRED   who with the mighty hand\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: he created\n",
      "TARGET mu-tu\n",
      "PRED   mu-tu\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: lugal an-sza-an u3 szuszin#\n",
      "TARGET king of Anshan and Susa:\n",
      "PRED   king of heaven with its four corners:\n",
      "------------------------------------------------\n",
      "QUERY  translate German to Sumerian: eingegangen\n",
      "TARGET mu-kux(DU)\n",
      "PRED   i3-kux(DU)\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Akkadian: of the entire land invited therein\n",
      "TARGET sza2 _kur_ gab-bi sza2 ina lib3-bi iq-ra-a-ni\n",
      "PRED   ma-tum kab-tam i-na lib3-bi\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: {d}nansze\n",
      "TARGET for Nanshe\n",
      "PRED   of Nanshe\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: that person may Nanna\n",
      "TARGET [lu2-ba {d}nanna]\n",
      "PRED   lu2-bi dnanna\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: pu-ru-se2-e _kalam_\n",
      "TARGET and the verdicts of the land\n",
      "PRED   the lands of the land\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: la2-ia3 1(disz) ur-{d}isztaran dumu du-du\n",
      "TARGET Deficit: 1 Ur-Ishtaran, son of Dudu\n",
      "PRED   the deficit: 1: Ur-Ishtaran, son of Dudu\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: {d}nansze-GIR2@g-gal maszkim\n",
      "TARGET Nanshe-GIRgal was the requisitioner\n",
      "PRED   Nanshe-GIRgal was enforcer\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: and those priests\n",
      "TARGET gudu4-be2-ne\n",
      "PRED   en-na-bi\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: Basket-of-tablets:\n",
      "TARGET pisan-dub-ba\n",
      "PRED   pisan-dub-ba\n",
      "------------------------------------------------\n",
      "QUERY  translate English to Sumerian: (total:) 13\n",
      "TARGET ($ blank space $) 1(u) 3(disz)\n",
      "PRED   1(u) 3(disz)\n"
     ]
    }
   ],
   "source": [
    "def sample(num_samples=100):\n",
    "    for i in range(min(num_samples, tests.num_rows)):\n",
    "        t = tests[i]\n",
    "    #     print(t)\n",
    "        src = t[\"source\"]\n",
    "        tgt = t[\"target\"]\n",
    "        query = src\n",
    "        pred = pipeline(query)[0][\"translation_text\"]\n",
    "        print(\"-\"*48)\n",
    "        print(\"QUERY \", query)\n",
    "        print(\"TARGET\", tgt)\n",
    "        print(\"PRED  \", pred)\n",
    "    #     break\n",
    "    \n",
    "sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/fak/Projects/cuneiform\n",
      "Configuration saved in /home/fak/Projects/cuneiform/config.json\n",
      "Model weights saved in /home/fak/Projects/cuneiform/pytorch_model.bin\n",
      "tokenizer config file saved in /home/fak/Projects/cuneiform/tokenizer_config.json\n",
      "Special tokens file saved in /home/fak/Projects/cuneiform/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/fak/Projects/cuneiform'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.abspath(\"../../cuneiform\")\n",
    "trainer.save_model(model_path)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /home/fak/Projects/cuneiform/tokenizer_config.json\n",
      "Special tokens file saved in /home/fak/Projects/cuneiform/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/fak/Projects/cuneiform/tokenizer_config.json',\n",
       " '/home/fak/Projects/cuneiform/special_tokens_map.json',\n",
       " '/home/fak/Projects/cuneiform/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
