{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Translator\n",
    "\n",
    "Based on: https://huggingface.co/docs/transformers/tasks/translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, datetime\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import TranslationPipeline\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"TrainTranslator.ipynb\"\n",
    "\n",
    "source_langs = set([\"akk\", \"elx\", \"sux\"])\n",
    "\n",
    "# target_langs = set([\"en\", \"it\", \"es\", \"fr\", \"de\"])\n",
    "target_langs = set([\"en\"])\n",
    "\n",
    "base_model_id = \"t5-base\"\n",
    "\n",
    "model_max_length = 256\n",
    "batch_size = 32\n",
    "num_train_epochs = 60\n",
    "\n",
    "is_bi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t5-base-akkelxsux-en-20220719-204449'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_id = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "flags = \"\"\n",
    "if is_bi:\n",
    "    flags += \"-bi\"\n",
    "model_id = f\"{base_model_id}{flags}-{''.join(sorted(list(source_langs)))}-{''.join(sorted(list(target_langs)))}-{date_id}\"\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, <torch.cuda.device at 0x7f24d9f9b0a0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_cuda = torch.cuda.is_available()\n",
    "device = torch.cuda.device(0) if has_cuda else \"cpu\"\n",
    "has_cuda, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 19 20:44:49 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 30%   40C    P8    29W / 350W |    168MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A       971      G   /usr/lib/xorg/Xorg                120MiB |\r\n",
      "|    0   N/A  N/A      1236      G   ...ome-remote-desktop-daemon        4MiB |\r\n",
      "|    0   N/A  N/A      1272      G   /usr/bin/gnome-shell               23MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_full = {\n",
    "    \"akk\": \"Akkadian\",\n",
    "    \"elx\": \"Elamite\",\n",
    "    \"sux\": \"Sumerian\",\n",
    "    \"akkts\": \"Akkadian\",\n",
    "    \"elxts\": \"Elamite\",\n",
    "    \"suxts\": \"Sumerian\",\n",
    "    \"en\": \"English\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"de\": \"German\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate Sumerian to Spanish: '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prefix(src_lang, tgt_lang):\n",
    "    s = lang_full[src_lang]\n",
    "    t = lang_full[tgt_lang]\n",
    "    return f\"translate {s} to {t}: \"\n",
    "    \n",
    "get_prefix(\"suxts\", \"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1f050c38726e6453\n",
      "Reusing dataset json (/home/fak/.cache/huggingface/datasets/json/default-1f050c38726e6453/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dd8cc0f96045f5ad5f5f4bfef72b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['p', 'a', 'l', 'sux', 'en', 'grc', 'fr', 'de', 'peo', 'grcts', 'akkts', 'es', 'elxts', 'elx', 'akk', 'qpn', 'peots', 'ug', 'ugts', 'it', 'suxts', 'qpnts', 'arc', 'arcts'],\n",
       "        num_rows: 91566\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations = load_dataset(\"json\", data_files=\"../data/translations.jsonl\")\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = [\n",
    "    (\"ā\", \"a\"),\n",
    "    (\"Ā\", \"a\"),\n",
    "    (\"ḫ\", \"h\"),\n",
    "    (\"Ḫ\", \"H\"),\n",
    "    (\"ī\", \"i\"),\n",
    "    (\"Ī\", \"I\"),\n",
    "#     (\"î\", \"i\"),\n",
    "#     (\"Î\", \"I\"),\n",
    "    (\"ř\", \"r\"),\n",
    "    (\"Ř\", \"R\"),\n",
    "    (\"š\", \"sh\"),\n",
    "    (\"Š\", \"Sh\"),\n",
    "    (\"ṣ\", \"sh\"),\n",
    "    (\"Ṣ\", \"Sh\"),\n",
    "    (\"ṭ\", \"t\"),\n",
    "    (\"Ṭ\", \"T\"),\n",
    "    (\"ū\", \"u\"),\n",
    "    (\"Ū\", \"U\"),\n",
    "]\n",
    "def replace_unsupported(text):\n",
    "    r = text\n",
    "    for s, t in replacements:\n",
    "        r = r.replace(s, t)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing akk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a15a604858b476db3eb993faa995cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing elx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefa3677f9424e3fa463c3767fe814a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing sux\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739de4c5ed7f4fdda2ad643f5e4a73bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 89419\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourceandtargets = []\n",
    "for s in source_langs:\n",
    "    print(\"Preparing\", s)\n",
    "    for t in tqdm(target_langs):\n",
    "        st_prefix = get_prefix(s, t)\n",
    "        ts_prefix = get_prefix(t, s)\n",
    "        for line in translations[\"train\"]:\n",
    "            ls = line[s]\n",
    "            lt = line[t]\n",
    "            if ls is not None and len(ls) > 0 and lt is not None and len(lt) > 0:\n",
    "                lt = replace_unsupported(lt)\n",
    "                if lt[-1] == \".\" or lt[-1] == \"!\" or lt[-1] == \";\" or lt[-1] == \",\":\n",
    "                    lt = lt[:-1]\n",
    "                sourceandtargets.append((st_prefix + ls, lt))\n",
    "                if is_bi:\n",
    "                    sourceandtargets.append((ts_prefix + lt, ls))\n",
    "                \n",
    "random.shuffle(sourceandtargets)\n",
    "all_translations = Dataset.from_dict({\"source\": [x[0] for x in sourceandtargets], \"target\": [x[1] for x in sourceandtargets]})\n",
    "all_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 80477\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target'],\n",
       "        num_rows: 8942\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations = all_translations.train_test_split(test_size=0.1)\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 8942\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tests = translations[\"test\"]\n",
    "original_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function should_test at 0x7f24f5d68ee0> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['translate Akkadian to ', 'translate Elamite to ', 'translate Sumerian to ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b0f6cfb8984403b3728ebf3549583c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 8942\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_starts = [f\"translate {lang_full[s]} to \" for s in source_langs]\n",
    "print(test_starts)\n",
    "\n",
    "def should_test(t):\n",
    "    return any(t[\"source\"].startswith(s) for s in test_starts)\n",
    "\n",
    "translations[\"test\"] = original_tests.filter(should_test)\n",
    "translations[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, model_max_length=model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad <pad> 0\n",
      "eos </s> 1\n",
      "unk <unk> 2\n"
     ]
    }
   ],
   "source": [
    "print(\"pad\", tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(\"eos\", tokenizer.eos_token, tokenizer.eos_token_id)\n",
    "print(\"unk\", tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72633e8a56184f0a9a99a15bbf4eb5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13959, 4823, 1258, 8603, 12, 1566, 10, 3, 122, 23, 18, 51, 173, 18, 2, 26, 2, 1635, 26, 1598, 1]\n",
      "[3156, 51, 173, 18, 7286, 26, 1598, 1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727811625e824d1ea3cfcd17733a913d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 80477\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8942\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc = 0\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    global ccc\n",
    "#     print(examples)\n",
    "    inputs = [example for example in examples[\"source\"]]\n",
    "    targets = [example for example in examples[\"target\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=model_max_length, truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=model_max_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    ccc += 1\n",
    "    if ccc == 1:\n",
    "        print(model_inputs[\"input_ids\"][0])\n",
    "        print(model_inputs[\"labels\"][0])\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_translations = translations.map(preprocess_function, batched=True)\n",
    "tokenized_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 8942\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_translations[\"train\"].remove_columns([\"source\", \"target\"])\n",
    "tokenized_translations[\"test\"].remove_columns([\"source\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 108)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_max_length = max([len(x[\"input_ids\"]) for x in tokenized_translations[\"train\"]])\n",
    "target_max_length = max([len(x[\"labels\"]) for x in tokenized_translations[\"train\"]])\n",
    "source_max_length, target_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3156, 51, 173, 18, 7286, 26, 1598, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_translations[\"train\"][0][\"labels\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_model_id, max_length=model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-base\",\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 3072,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"max_length\": 256,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.19.4\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "# data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"../results/{model_id}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2*2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    fp16=has_cuda,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_translations[\"train\"],\n",
    "    eval_dataset=tokenized_translations[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/fak/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 80477\n",
      "  Num Epochs = 60\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150900\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpraeclarum\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/fak/Projects/CuneiformTranslators/tools/wandb/run-20220719_204545-2n8yp7y3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/praeclarum/huggingface/runs/2n8yp7y3\" target=\"_blank\">../results/t5-base-akkelxsux-en-20220719-204449</a></strong> to <a href=\"https://wandb.ai/praeclarum/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59416' max='150900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 59416/150900 2:10:44 < 3:21:19, 7.57 it/s, Epoch 23.62/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.662100</td>\n",
       "      <td>2.420769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.335900</td>\n",
       "      <td>2.141625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.145900</td>\n",
       "      <td>1.992723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.995200</td>\n",
       "      <td>1.892020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.873400</td>\n",
       "      <td>1.810962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.804600</td>\n",
       "      <td>1.752047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.710500</td>\n",
       "      <td>1.706529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.642900</td>\n",
       "      <td>1.665118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.574800</td>\n",
       "      <td>1.636691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.518400</td>\n",
       "      <td>1.611390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.482300</td>\n",
       "      <td>1.591857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.437700</td>\n",
       "      <td>1.572682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.400800</td>\n",
       "      <td>1.552400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.335200</td>\n",
       "      <td>1.541942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.321900</td>\n",
       "      <td>1.528275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.290600</td>\n",
       "      <td>1.519377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.257100</td>\n",
       "      <td>1.506903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.222500</td>\n",
       "      <td>1.499046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.204000</td>\n",
       "      <td>1.494063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.172800</td>\n",
       "      <td>1.488134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.151600</td>\n",
       "      <td>1.495364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.118700</td>\n",
       "      <td>1.474516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.098500</td>\n",
       "      <td>1.449693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3000] due to args.save_total_limit\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-8500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-13500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-17500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-18500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-21500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-23500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-25500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-27500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-28500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-29500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-33500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-36500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-38500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-42500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-43500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-44500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-46500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-47500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-48500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-49500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-50500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-51500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-52500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-53500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-54500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-55500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8942\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-56500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58500\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58500/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58500/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58500/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-58500/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-59000\n",
      "Configuration saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-59000/config.json\n",
      "Model weights saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-59000/pytorch_model.bin\n",
      "tokenizer config file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-59000/tokenizer_config.json\n",
      "Special tokens file saved in ../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-59000/special_tokens_map.json\n",
      "Deleting older checkpoint [../results/t5-base-akkelxsux-en-20220719-204449/checkpoint-57500] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1317\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1314\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1316\u001b[0m )\n\u001b[0;32m-> 1317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1554\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1554\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1557\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1560\u001b[0m ):\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2193\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2190\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_grad_scaling:\n\u001b[0;32m-> 2193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_apex:\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mscale_loss(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer) \u001b[38;5;28;01mas\u001b[39;00m scaled_loss:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TranslationPipeline(model=model.to(\"cpu\"), tokenizer=tokenizer, max_length=model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text2text_generation.TranslationPipeline at 0x7f24781c8f70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': '(Say) hi, my name is Frank'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"translate English to French: hello my name is Frank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate Sumerian to English: {d}szul-gi\n",
      "--------------------------------------------------------------------------------\n",
      "Shulgi\n"
     ]
    }
   ],
   "source": [
    "source_test = translations[\"test\"][0][\"source\"]\n",
    "target_test = translations[\"test\"][0][\"target\"]\n",
    "print(source_test)\n",
    "print(\"-\"*80)\n",
    "print(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Shulgi'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(text):\n",
    "    return pipeline(text)\n",
    "\n",
    "translate(source_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: {d}szul-gi\n",
      "TARGET Shulgi\n",
      "PRED   Shulgi\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: lugal ki-en-gi ki-uri\n",
      "TARGET king of Sumer and Akkad\n",
      "PRED   and king of Sumer and Akkad\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ra-bi-isz e-pu-usz\n",
      "TARGET and I rebuilt them in a grand fashion\n",
      "PRED   I did a great job\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _kiszib3_ qar-dum-{d}iszkur\n",
      "TARGET seal of Qardum-Adad\n",
      "PRED   Seal of Qardum-Adad\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na har-ra-ni sza a-lak-ta-sza2 la ta-a-a-rat\n",
      "TARGET to the route whose path is one of he who does not return\n",
      "PRED   to the harrani drum of her ablutions ceased\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u2-gal-lib2-ma kal pe-er-ti szu-me-lam [...]\n",
      "TARGET he cut off all the hair on the left and ...\n",
      "PRED   I made it abundantly abundant with offerings and ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: lu2# du14-da-ka-a-ni\n",
      "TARGET is the one of (i.e., object of) his quarreling\n",
      "PRED   When the one of the “throat”(?) arrives(?)\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [...] x [...]-ma\n",
      "TARGET ..\n",
      "PRED   ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _{uzu}ur2 {uzu}kusz#_\n",
      "TARGET (the sangû priest’s portion is): a thigh, the hide\n",
      "PRED   of the ribs and joints\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _lugal_-ki-ma-ka-li-ma\n",
      "TARGET Sharrum-kima-kalima\n",
      "PRED   Lugal-kima-kali-sharri\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: dumu-gu10# [...] na-an#-[...]\n",
      "TARGET My son, one should not rob\n",
      "PRED   My son, may he not ... for him\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: za-e ku6# nam-ba-gu7#-[...]\n",
      "TARGET You, do not eat fish, ..\n",
      "PRED   You are the one who eats fish(?)\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: u2-li-id me-er-ha\n",
      "TARGET bore the seed\n",
      "PRED   a kind of fungus\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ur-gin7 {gesz}az-la2-e mu-un-dab5 me-a lu2 mu-un-gar\n",
      "TARGET Like a dog kept in a cage, she is silenced\n",
      "PRED   like dogs took off to slaughter, a man seized me\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: u4 te-esz du11-ga kalam tesz2-a gar-ra\n",
      "TARGET The roaring storm that subjugates the entire land\n",
      "PRED   The storm which annihilates the Land is set in order\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 1(disz) 1/3(disz) ma-na su-he2\n",
      "TARGET 1 1/3 mana suhe\n",
      "PRED   (and) 1 1/3 minas of tin\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ki-i pi-i _gal-mesz_\n",
      "TARGET according to the word of the nobles\n",
      "PRED   as many as there are\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {iti}kin _2(disz)-kam2 u4 1(u)-kam2_\n",
      "TARGET intercalary Ululu, 10th day\n",
      "PRED   of Elunum the 2nd day, 10th day\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ug3-e u2 nir-gal2 bi2-ib2-gu7?-en {d}en-ki-im-du-bi-me-en\n",
      "TARGET I cause the people to eat splendid food; I am their Enkimdu (i.e. the god of irrigation and cultivation)\n",
      "PRED   You are a god who loves to eat(?) food\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: AN#?-[...]\n",
      "TARGET ..\n",
      "PRED   ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: {d}in-nin ag2 ze2-eb-be2-da-mu me al nu-di-di nig2-mu mu-ra-an-gar = %a _{d}min_ ur-tu4 ka-bit-tu4 pa-ra-as, la e-re-szi mim-me-e-a a-szim-ki\n",
      "TARGET Lady, I have established for you my weighty commands, divine powers that should not be demanded by anyone\n",
      "PRED   Lady who adores sweet words, who establishes a favoured destiny for you\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 1(esze3) GAN2 6(asz) gur lu2-du10-ga dumu lugal-{gesz}kiri6\n",
      "TARGET 1 eshe3 field area: 6 gur, Lu-duga, son of Lugal-kiri6\n",
      "PRED   1 eshe3 surface area, 6 gur, Lu-duga, son (of) Lugal-des-Gesh\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: sze lugal-uszur3\n",
      "TARGET (it is the) barley of Lugal-Ushur\n",
      "PRED   barley of Lugal-ushur\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [alan] ne2-ne2\n",
      "TARGET upon the statue of so-and-so\n",
      "PRED   who the statue of so-and-so\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: szir3!? ku3-ga2-ke4-esz# [...]-de3#-en\n",
      "TARGET I am to “die” because of my holy song\n",
      "PRED   Therefore(?) I shall praise my pure/bestowed(?) song\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 3(N34@f) 2(N14@f) 4(N01@f) , lu2 RU\n",
      "TARGET 204 men subscripted (?)\n",
      "PRED   3 (men?): 92 (men) ...\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 1(disz) sa szum2\n",
      "TARGET 1 bundle onions\n",
      "PRED   1 bundle onions\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: s,e-eh-ra-am\n",
      "TARGET a young child\n",
      "PRED   the sick\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 7(asz) <ugula> gu-za-la2\n",
      "TARGET 7, foreman of throne bearers\n",
      "PRED   7, foreman of throne bearers\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: la uk-ti-in-szu\n",
      "TARGET has not proven it\n",
      "PRED   did not give him\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: esz3 e2-babbar-[ra]\n",
      "TARGET of the shrine Ebabbar\n",
      "PRED   the shrine Ebabbar\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: nu-[banda3-gu4 ...]\n",
      "TARGET oxen-manager ..\n",
      "PRED   the oxen manager ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _kisz_\n",
      "TARGET of the world\n",
      "PRED   of the world\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: kiszib3 ur-{d}szara2 sza13-dub-ba\n",
      "TARGET under seal of Ur-Shara, chief accountant\n",
      "PRED   under seal of Ur-Shara, the archivist\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ARAD2-{d}nanna\n",
      "TARGET ARAD-Nanna\n",
      "PRED   (for) Warad-Nanna\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: di#-til-la inim pu-uh2-ru-ma-ka szu gi4-gi4 nu-gal2\n",
      "TARGET There is no revocation of a final verdict, the word of the assembly\n",
      "PRED   The judgment of judgment (?) was not binding(?)\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [...] ib2-szi-ag2-ge26-a\n",
      "TARGET shall order against it\n",
      "PRED   shall issue against it\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: sza3-gal kas4-e-ne\n",
      "TARGET provisions for messengers\n",
      "PRED   the supporter of runners\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-szid lu-u2-tu it-ta-sah ki-ma szam-mi\n",
      "TARGET the base of debility he tore out like grass\n",
      "PRED   they swore that I would be annihilated, as a fictitious one\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: gal-le-esz mu-na-an-gun3\n",
      "TARGET and made it grandly colorful\n",
      "PRED   greatly he had awe-inspiring praise\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na be-li-ni ni-isz#-[pu-ra]-am#\n",
      "TARGET wrote to our lord:\n",
      "PRED   to our lord we shall send\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 3(disz) geme2-sze-il2-la\n",
      "TARGET 3 (mana wool for) Geme-she’ila\n",
      "PRED   (and) 3 (for) Geme-she’ila\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: a#-pi4-sal4{ki}\n",
      "TARGET Apisal\n",
      "PRED   Apisal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 8(asz@c)# kusz3#-numun# [sa2]\n",
      "TARGET 8 seed-cubits squared:\n",
      "PRED   8 seed-cubits squared:\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: i-na ne2-kur-ti _lu2_ ha-szi-[im{ki}]\n",
      "TARGET in hostilities with the Man of Hashshum\n",
      "PRED   In the midst of the Hashumu people\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: e2 dingir gal-gal-e-ne-ka\n",
      "TARGET the temples of the great gods\n",
      "PRED   (and) the temples of the great gods\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: {disz}e2-a-tu-ra-am u3 e2-a-ta-a-a-ar\n",
      "TARGET Ea-turam and Ea-tayar\n",
      "PRED   Ea-turam and Ea-tura\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 4(disz) ad7 gu4\n",
      "TARGET 4 carcasses of oxen\n",
      "PRED   4 carcasses of oxen\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: i3-gal2\n",
      "TARGET are here\n",
      "PRED   are here\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ku-du-ur-ma-bu-uk!(BI)\n",
      "TARGET (and also of) Kudur-mabuk\n",
      "PRED   (for) Kudur-mabuk\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: 1(u) 2(asz) 1(ban2) [...]\n",
      "TARGET 12 gur 1 ban2 ..\n",
      "PRED   (and) ten (gur) 1 ban2 ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [nam-bi mu-un-tar]-ra-a\n",
      "TARGET fate had decreed\n",
      "PRED   which decrees its fate\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: a-na zimbir{ki}\n",
      "TARGET all the way up to Sippar\n",
      "PRED   for Sippar\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [x]-an-[na]-tum2\n",
      "TARGET Eanatum (or Enanatum)\n",
      "PRED   x-anatum\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ki# ur-mes gudu4-ta\n",
      "TARGET from Ur-mes, the gudu4-priest\n",
      "PRED   from Ur-mes, the messenger(?)\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: {d}nin-hur-sag-ke4 igi zi ba-szi-bar\n",
      "TARGET Ninhursag had looked on it in a friendly way\n",
      "PRED   Ninhursaga looked at her with a gleaming face\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [...]-da#?-gu10 he2#-eb-x [...]\n",
      "TARGET ..\n",
      "PRED   My lady, may(?) my ... be ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: {d}en-lil2-le kur-kur-ra inim gal-gal-sze3 kig2-gi4-a bi2-in-gi4\n",
      "TARGET Enlil had sent her as a messenger to all the foreign lands concerning very important matters.”\n",
      "PRED   Enlil has restored to its place by addressing the lands with great understanding\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ne-te-ni bi2-zu\n",
      "TARGET he showed who he was\n",
      "PRED   who knows the command\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: {disz}SZUBUR\n",
      "TARGET A pig\n",
      "PRED   ...\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {disz}u2-ri-ia-ik-ki {kur}qu-u2-a-a {disz}pi-si-ri-is {iri}gar-ga-misz-a-a {disz}e-ni-il3 {iri}ha-am-ma-ta-a-a {disz}pa-na-am-mu-u {iri}sa-am-'a-la-a-a\n",
      "TARGET Uriyikki (Urikki) of (the land) Que, Pisiris of (the city) Carchemish, Eni-il of (the city) Hamath, Panammû of (the city) Sam’al\n",
      "PRED   Urikki, the Quay, Pishiriya, Gargamish, Enid, Amatat, Panamu, Asaya\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: mu-ne-sze3\n",
      "TARGET of mine\n",
      "PRED   and to their benevolent\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: lugal uri5{ki}-ma\n",
      "TARGET king of Ur\n",
      "PRED   king of Ur\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [...] x\n",
      "TARGET ..\n",
      "PRED   ..\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: sza a-ka-li-im\n",
      "TARGET provisions\n",
      "PRED   of the akalum\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: kal-ga si-ga-bi\n",
      "TARGET Their strong and weak\n",
      "PRED   its strongest one\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [...] ezem# gal2-la-zu [...] x du10-ga-am3\n",
      "TARGET (During) the first month of the year, when your festival takes place, ... is good\n",
      "PRED   Your festival is good, your festival is good\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: dumu szi-x-[...]\n",
      "TARGET son of ..\n",
      "PRED   son of Shi-...\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: usz-te-zi-ib\n",
      "TARGET has left\n",
      "PRED   shall be piled up\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: isz-tu4\n",
      "TARGET From\n",
      "PRED   from\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _lugal kisz_\n",
      "TARGET the king of the world\n",
      "PRED   king of the world\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: nam-ti-la-ni-sze3\n",
      "TARGET for his (Lugalzagesi’s) life\n",
      "PRED   for his life\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 2(bur3) 2(esze3) GAN2 1(u)-ta\n",
      "TARGET 2 bur3 2 eshe3 surface area, 10 each\n",
      "PRED   2 bur3 2 eshe3 surface area at 10 each\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ziz2-bi 1(u) 4(asz) gur\n",
      "TARGET its emmer: 14 gur\n",
      "PRED   its emmer: 14 gur\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: mu sza-asz-szu2-ru-um{ki} ba-hul#\n",
      "TARGET year: “Shashrum was destroyed.”\n",
      "PRED   year: “Shashrum was destroyed.”\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u3 lu sze-er-ha-nam\n",
      "TARGET or a muscle\n",
      "PRED   or the dowry\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: ni-qum{ki}\n",
      "TARGET of Niqqum\n",
      "PRED   Niqqum\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: lugal ki-en-gi ki-uri\n",
      "TARGET and king of Sumer and Akkad\n",
      "PRED   and king of Sumer and Akkad\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: [a-li2]-tim#\n",
      "TARGET the Upper\n",
      "PRED   (and) the Upper\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _{gesz}gu-za_-am\n",
      "TARGET A chair\n",
      "PRED   the chair\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: 4(ban2) 2(disz) sila3 u2-kur\n",
      "TARGET 4 ban2 2 sila3 u2-kur spice\n",
      "PRED   4 ban2, 2 sila3 of Ukur\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: URU-KA-gi-na\n",
      "TARGET URU-KA-gina\n",
      "PRED   URU-KA-gina\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: nin mi2 du11-ga dingir-re-e-ne\n",
      "TARGET the cherished lady of the gods\n",
      "PRED   the lady who makes a claim among the gods\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: iri ku3-ga\n",
      "TARGET in the Holy City\n",
      "PRED   the Holy City\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u {d}da-gan ka-szu-usz _dingir-mesz gal-mesz man_ dan-nu _man szu2 man kur_ asz-szur _a_ tukul-masz _man gal_-e\n",
      "TARGET and Dagan, destructive weapon of the great gods, strong king, king of the universe, king of Assyria, son of Tukulti-Ninurta, great king\n",
      "PRED   and Dagan, elder brother of the great gods, strong man, mighty king, king of the universe, king of Assyria, son of Tukultanmasz, great king\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: sumun2\n",
      "TARGET wild cow\n",
      "PRED   a kind of acrid\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: sza a-na _e2_ e-me-szu iz-bi-lu-u2-ni\n",
      "TARGET who to the household of his father-in-law presented\n",
      "PRED   who to his house of wailing he shall bring\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: lugal-gesz\n",
      "TARGET Lugal-gish\n",
      "PRED   the kings\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: {d}hu-bu-ur\n",
      "TARGET the god Hubur\n",
      "PRED   of Huhurur\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: alan sa6-ga\n",
      "TARGET beautiful statues\n",
      "PRED   a beautiful statue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: u4-ba\n",
      "TARGET then\n",
      "PRED   At that time\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: e2 an-sze3 1(szar'u) GAN2 ki-sze3 5(szar2) GAN2\n",
      "TARGET House, 10 shar2 area at its upper end, 5 shar2 area at its lower end\n",
      "PRED   Temple, towards the sky it is 1 shar2, towards the earth it is 5 shar2\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: gu2 ki gal2-la-ba ba-e-sug2-esz kur-re ba-ab-DU-DU-na-esz\n",
      "TARGET They stood in the manner of one whose neck is pushed to the ground(?) the mountain(dwellers?) carried(?) them away\n",
      "PRED   They were bound up in their folds, they were bound up in the netherworld\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: u3 u3-sza-asz2-t,a2-ru\n",
      "TARGET or shall cause it to be written\n",
      "PRED   and I shall levy\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: na-ru2-a-bi\n",
      "TARGET Its steles\n",
      "PRED   Its stela\n",
      "------------------------------------------------\n",
      "QUERY  translate Akkadian to English: _igi_ {disz}sanga!-1(u)-5(disz) _igi_ {disz}{d}pa-ka-min-pab\n",
      "TARGET before Sangî-Issar, before Nabû-pi-ahi-ushur\n",
      "PRED   before Sangi-il-i(n)-shumi, before Nabu-kamin-pabb\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ensi2 gir2-su{ki#}\n",
      "TARGET of the governor of Girsu\n",
      "PRED   governor of Girsu\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: [gesz tag-ga] = %a li-ip-tum\n",
      "TARGET offering\n",
      "PRED   rope\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: a-na\n",
      "TARGET to\n",
      "PRED   (this seal)\n",
      "------------------------------------------------\n",
      "QUERY  translate Sumerian to English: ki bi2-in-gul-la-gin7 ki nam-ga-bi2-ib2-gul-en\n",
      "TARGET I too shall destroy the place like the one who has destroyed places\n",
      "PRED   As if destroyed there were not to be rebuilt(?)\n"
     ]
    }
   ],
   "source": [
    "tests = original_tests\n",
    "def sample(num_samples=100):\n",
    "    for i in range(min(num_samples, tests.num_rows)):\n",
    "        t = tests[i]\n",
    "    #     print(t)\n",
    "        src = t[\"source\"]\n",
    "        tgt = t[\"target\"]\n",
    "        query = src\n",
    "        pred = pipeline(query)[0][\"translation_text\"]\n",
    "        print(\"-\"*48)\n",
    "        print(\"QUERY \", query)\n",
    "        print(\"TARGET\", tgt)\n",
    "        print(\"PRED  \", pred)\n",
    "    #     break\n",
    "    \n",
    "sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.abspath(\"../../cuneiform\")\n",
    "trainer.save_model(model_path)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
