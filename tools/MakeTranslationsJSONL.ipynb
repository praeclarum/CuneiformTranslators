{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81f148c0",
   "metadata": {},
   "source": [
    "# Make Translations JSONL\n",
    "\n",
    "Outputs human translations to the data folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca67a243",
   "metadata": {},
   "source": [
    "http://oracc.museum.upenn.edu/doc/help/editinginatf/primer/inlinetutorial/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e546ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import importlib\n",
    "import torch\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TranslationPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58398084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import languages\n",
    "import cdli\n",
    "import oracc\n",
    "import corpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc7b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb9269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_langs = set([\"akk\", \"sux\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cd371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracc_corpus = corpi.ORACC(oracc_dir=\"/Volumes/FrankDisk/oracc_zips\", tqdm=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bc1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdli_corpus = corpi.CDLI(tqdm=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70691bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CDLI lines to paragraphs\n",
    "for pub in cdli_corpus.cdli_pubs.values():\n",
    "    for a in pub.text_areas:\n",
    "        a.lines_to_paragraphs(pub.language, \"en\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02d7a2f2",
   "metadata": {},
   "source": [
    "## Test Normalized ORACC Transliterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d81b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object_ids = [\n",
    "    \"Q003230\", # Asshur\n",
    "    \"P250815\", # szag4 to sza3, kud to ku5\n",
    "    \"P271132\", # geme2 to dam\n",
    "    \"P332924\", # gab2 to kab, zid to zi, tum12 to tu\n",
    "    \"P271187\", # tu4 to tum, ir3 to ARAD2\n",
    "    \"P271030\", # pu to bu\n",
    "    \"P228726\", # sag10 to saga, gurum to gur2, ah3 to had2\n",
    "    \"P247541\", # giggi to kukku5\n",
    "    \"P503256\", # Links in cuneiform\n",
    "    \"P237767\",\n",
    "    \"P503256\",\n",
    "    \"P237730\",\n",
    "\n",
    "    \"P010627\", # Notes: o ii 66\n",
    "\n",
    "    \"Q000041\",\n",
    "    \"Q000057\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93323ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Q003230\n"
     ]
    }
   ],
   "source": [
    "for t in test_object_ids[:1]:\n",
    "    pub = oracc_corpus.oracc_pubs[t]\n",
    "    print(\"-\"*80)\n",
    "    print(pub.id)\n",
    "    for a in pub.text_areas:\n",
    "        paras = a.paragraphs_to_lines(pub.language, pub.corpus)\n",
    "        for pi, plines in enumerate(paras):\n",
    "            # for si, ei, line in plines:\n",
    "            #     print(line)\n",
    "            para = a.paragraphs[pi]\n",
    "            en_text = a.paragraphs[pi].languages[\"en\"]\n",
    "            en_lines = en_text.split(\"\\n\")\n",
    "            # print(f\"Para lines: {para.start_line_index} - {para.end_line_index} ({para.end_line_index - para.start_line_index}) and {len(en_lines)} en lines\")\n",
    "            # for li in range(para.start_line_index, para.end_line_index):\n",
    "            #     if li < len(a.lines):\n",
    "            #         print(f\"{pub.language}{li}: {a.lines[li].text}\")\n",
    "            # for li, line in enumerate(en_lines):\n",
    "            #     print(f\"en{li}: {line}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79566e22",
   "metadata": {},
   "source": [
    "## Show CDLI and ORACC Corpi Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a5b5345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5363, 'cdli translated pubs')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdli_translated_pubs = {x.id: x for x in cdli_corpus.cdli_pubs.values() if x.is_translated(\"en\")}\n",
    "len(cdli_translated_pubs), \"cdli translated pubs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93ad902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "                   lang: sux\n",
      "\n",
      "    transliterated cdli: 99,808\n",
      "        translated cdli: 4,151\n",
      " need translations cdli: 95,611\n",
      "\n",
      "   transliterated oracc: 3,513\n",
      "       translated oracc: 443\n",
      "need translations oracc: 3,039\n",
      "------------------------------------------\n",
      "                  total: 103,075\n",
      "   transliterated total: 103,075\n",
      "       translated total: 4,583\n",
      "need translations total: 98,492\n",
      "==========================================\n",
      "                   lang: akk\n",
      "\n",
      "    transliterated cdli: 21,945\n",
      "        translated cdli: 972\n",
      " need translations cdli: 20,937\n",
      "\n",
      "   transliterated oracc: 12,007\n",
      "       translated oracc: 9,098\n",
      "need translations oracc: 2,906\n",
      "------------------------------------------\n",
      "                  total: 31,747\n",
      "   transliterated total: 31,747\n",
      "       translated total: 10,069\n",
      "need translations total: 21,678\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def show_language_stats(src_lang, tgt_lang=\"en\"):\n",
    "    transliterated_cdli_index = {x.id: x for x in cdli_corpus.cdli_pubs.values() if x.language == src_lang}\n",
    "    transliterated_cdli_ids = set(transliterated_cdli_index.keys())\n",
    "    transliterated_oracc_index = {x.id: x for x in oracc_corpus.oracc_pubs.values() if x.language == src_lang}\n",
    "    transliterated_oracc_ids = set(transliterated_oracc_index.keys())\n",
    "    all_transliterated_ids = transliterated_cdli_ids.union(transliterated_oracc_ids)\n",
    "\n",
    "    translated_cdli_index = {x.id: x for x in transliterated_cdli_index.values() if x.is_translated(tgt_lang=tgt_lang)}\n",
    "    translated_cdli_ids = set(translated_cdli_index.keys())\n",
    "    translated_oracc_index = {x.id: x for x in transliterated_oracc_index.values() if x.is_translated(tgt_lang=tgt_lang)}\n",
    "    translated_oracc_ids = set(translated_oracc_index.keys())\n",
    "    all_translated_ids = translated_cdli_ids.union(translated_oracc_ids)\n",
    "    \n",
    "    cdli_needs_translation_ids = transliterated_cdli_ids.difference(all_translated_ids)\n",
    "    oracc_needs_translation_ids = transliterated_oracc_ids.difference(all_translated_ids)\n",
    "    all_needs_translation_ids = cdli_needs_translation_ids.union(oracc_needs_translation_ids)\n",
    "    \n",
    "#     cdli_ids = set(x[0] for x in cdli_pub_ids_and_langs if x[1] == src_lang)\n",
    "\n",
    "    print(\"=\"*42)\n",
    "    print(f\"                   lang: {src_lang}\")\n",
    "    print()\n",
    "#     print(f\"                   cdli: {len(cdli_ids)}\")\n",
    "    print(f\"    transliterated cdli: {len(transliterated_cdli_ids):,}\")\n",
    "    print(f\"        translated cdli: {len(translated_cdli_ids):,}\")\n",
    "    print(f\" need translations cdli: {len(cdli_needs_translation_ids):,}\")\n",
    "\n",
    "    print()\n",
    "    print(f\"   transliterated oracc: {len(transliterated_oracc_ids):,}\")\n",
    "    print(f\"       translated oracc: {len(translated_oracc_ids):,}\")\n",
    "    print(f\"need translations oracc: {len(oracc_needs_translation_ids):,}\")\n",
    "    print(\"-\"*42)\n",
    "    print(f\"                  total: {len(all_transliterated_ids):,}\")\n",
    "    print(f\"   transliterated total: {len(all_transliterated_ids):,}\")\n",
    "    print(f\"       translated total: {len(all_translated_ids):,}\")\n",
    "    print(f\"need translations total: {len(all_needs_translation_ids):,}\")\n",
    "\n",
    "show_language_stats(src_lang=\"sux\")\n",
    "show_language_stats(src_lang=\"akk\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6f5a976",
   "metadata": {},
   "source": [
    "## Test Tokenization of Sources and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44779b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"praeclarum/cuneiform\"\n",
    "model_revision = \"7a60be19efe61bf4adf873eb86f864ea7bfb4876\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3363d004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=model_revision, device=-1)\n",
    "model_max_length = tokenizer.model_max_length\n",
    "model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66bfa3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'languages' from '/Users/fak/Dropbox/Projects/CuneiformTranslators/tools/languages.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f5b2b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't tokenize text: the gods Aššur Sîn Šamaš Bēl and Nabû Ištar of Nineveh (and) Ištar of Arbela\n",
      "                               ^ unicode \\u0161\n",
      "                     the gods A<unk>ur Sîn <unk>ama<unk> B<unk>l and Nabû I<unk>tar of Nineveh (and) I<unk>tar of Arbela\n",
      "Can tokenize text: the gods Ashur Sîn Shamash Bel and Nabû Ishtar of Nineveh (and) Ishtar of Arbela\n"
     ]
    }
   ],
   "source": [
    "def can_tokenize(text):\n",
    "    text = text.strip()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # print(tokens)\n",
    "    dec_text = tokenizer.decode(tokens).strip()\n",
    "    # print(dec_text)\n",
    "    if dec_text.endswith(\"</s>\"):\n",
    "        dec_text = dec_text[:-4]\n",
    "    text = text.replace(\"…\", \"...\")\n",
    "    text = languages.remove_extraneous_space(text.replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\"))\n",
    "    dec_text = languages.remove_extraneous_space(dec_text.replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\"))\n",
    "    if dec_text != text:\n",
    "        return False, text, dec_text\n",
    "    return True, text, dec_text\n",
    "\n",
    "def test_tokenize(text, title=\"text\", verbose=False):\n",
    "    can, text, dec = can_tokenize(text)\n",
    "    if not can:\n",
    "        # Find the problematic character\n",
    "        good_end_index = 0\n",
    "        ti = 0\n",
    "        di = 0\n",
    "        while ti < len(text) and di < len(dec):\n",
    "            d = dec[di]\n",
    "            t = text[ti]\n",
    "            if t == d:\n",
    "                good_end_index = ti\n",
    "                ti += 1\n",
    "                di += 1\n",
    "            else:\n",
    "                if d == \" \" and di + 1 < len(dec) and dec[di+1] == t:\n",
    "                    good_end_index = ti\n",
    "                    di += 2\n",
    "                    ti += 1\n",
    "                elif t == \" \" and ti + 1 < len(text) and text[ti+1] == d:\n",
    "                    good_end_index = ti + 1\n",
    "                    ti += 2\n",
    "                    di += 1\n",
    "                else:\n",
    "                    break\n",
    "        if good_end_index + 1 < len(text):\n",
    "            head = f\"Can't tokenize {title}: \"\n",
    "            print(f\"{head}{text}\")\n",
    "            print(f\"{' '*len(head)}{' '*(good_end_index+1)}^ unicode \\\\u{ord(text[good_end_index+1]):04x}\")\n",
    "            print(f\"{' '*len(head)}{dec}\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"Can tokenize {title}: {text}\")\n",
    "test_tokenize(\"the gods Aššur, Sîn, Šamaš, Bēl, and Nabû, Ištar of Nineveh, (and) Ištar of Arbela\", verbose=True)\n",
    "test_tokenize(languages.replace_unsupported_en(\"the gods Aššur, Sîn, Šamaš, Bēl, and Nabû, Ištar of Nineveh, (and) Ištar of Arbela\"), verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7553617",
   "metadata": {},
   "source": [
    "## Output Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e524a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_out_dir = f\"../data\"\n",
    "os.makedirs(translations_out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "268eb786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'languages' from '/Users/fak/Dropbox/Projects/CuneiformTranslators/tools/languages.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93cd55b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015339136123657227,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 150705,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e5d730d3aa4009a7c313bf587db68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest line length: 5886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116804"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_translations(tgt_lang=\"en\"):\n",
    "    srcs = set()\n",
    "    translations = defaultdict(list)\n",
    "    longest_line_len = 0\n",
    "\n",
    "    all_pubs = list(cdli_corpus.cdli_pubs.values()) + list(oracc_corpus.oracc_pubs.values())\n",
    "\n",
    "    for pub in tqdm(all_pubs):\n",
    "        if pub.language not in supported_langs:\n",
    "            continue\n",
    "        for a in pub.text_areas:\n",
    "            for p in a.paragraphs:\n",
    "                if tgt_lang in p.languages:\n",
    "                    src_lines = [x.text for x in a.lines[p.start_line_index:p.end_line_index]]\n",
    "                    src = \" \".join(src_lines)\n",
    "                    src = languages.prep_src_for_nn(src, pub.language, pub.corpus)\n",
    "                    # test_tokenize(src, \"source\")\n",
    "\n",
    "                    tgt = p.languages[tgt_lang]\n",
    "                    tgt = languages.prep_tgt_for_nn(tgt, tgt_lang, pub.corpus)\n",
    "                    # test_tokenize(tgt, \"target\")\n",
    "                    \n",
    "                    if len(src) > 0 and languages.target_ok(tgt) and src not in srcs:\n",
    "                        line_len = len(src)\n",
    "                        longest_line_len = max(line_len, longest_line_len)\n",
    "                        out_line = json.dumps({pub.language:src,tgt_lang:tgt})\n",
    "                        # if pub.id == \"Q003230\":\n",
    "                        #     print(f\"Q003230: {out_line}\")\n",
    "                        translations[pub.language].append(out_line)\n",
    "                        srcs.add(src)\n",
    "                        \n",
    "    print(f\"longest line length:\", longest_line_len)\n",
    "\n",
    "    for src_lang in translations.keys():\n",
    "        path = f\"{translations_out_dir}/translations_{src_lang}_to_{tgt_lang}.jsonl\"\n",
    "\n",
    "        with open(path, \"wt\") as f:\n",
    "            head = \"\"\n",
    "            for out_line in sorted(translations[src_lang]):\n",
    "                f.write(head)\n",
    "                f.write(out_line)\n",
    "                head = \"\\n\"\n",
    "\n",
    "    return sum(len(translations) for translations in translations.values())\n",
    "    \n",
    "output_translations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158a56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c980a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
